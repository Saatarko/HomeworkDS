{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9167c84b-351b-4afc-bef6-419aae8f5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Отключает все логи TensorFlow (0 - все, 1 - предупреждения, 2 - ошибки, 3 - критичные ошибки)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb739c26-65d1-4e14-b697-bc3a5a65d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune_tensorflow_keras import NeptuneCallback  \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Union\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import neptune\n",
    "import optuna\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray import train\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from dotenv import load_dotenv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f04d2c4-49de-4dde-9b26-794f69c61b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paris = pd.read_csv('content/ParisHousing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613ffb1a-526b-4926-a333-a64d8882a1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75523</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>9373</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4313</td>\n",
       "      <td>9005</td>\n",
       "      <td>956</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7559081.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80771</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>39381</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3653</td>\n",
       "      <td>2436</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8085989.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55712</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>34457</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2937</td>\n",
       "      <td>8852</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5574642.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32316</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27939</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>7141</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3232561.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70429</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>38045</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8435</td>\n",
       "      <td>2429</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7055052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1726</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>73133</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9311</td>\n",
       "      <td>1698</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>176425.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>44403</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>34606</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9061</td>\n",
       "      <td>1742</td>\n",
       "      <td>230</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4448474.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>83841</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>80933</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2005</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8304</td>\n",
       "      <td>7730</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8390030.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>59036</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>55856</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2590</td>\n",
       "      <td>6174</td>\n",
       "      <td>339</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5905107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1440</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>18412</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8485</td>\n",
       "      <td>2024</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>146708.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0            75523              3        0        1      63      9373   \n",
       "1            80771             39        1        1      98     39381   \n",
       "2            55712             58        0        1      19     34457   \n",
       "3            32316             47        0        0       6     27939   \n",
       "4            70429             19        1        1      90     38045   \n",
       "...            ...            ...      ...      ...     ...       ...   \n",
       "9995          1726             89        0        1       5     73133   \n",
       "9996         44403             29        1        1      12     34606   \n",
       "9997         83841              3        0        0      69     80933   \n",
       "9998         59036             70        0        0      96     55856   \n",
       "9999          1440             84        0        0      49     18412   \n",
       "\n",
       "      cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0                 3              8  2005           0                  1   \n",
       "1                 8              6  2015           1                  0   \n",
       "2                 6              8  2021           0                  0   \n",
       "3                10              4  2012           0                  1   \n",
       "4                 3              7  1990           1                  0   \n",
       "...             ...            ...   ...         ...                ...   \n",
       "9995              7              6  2009           0                  1   \n",
       "9996              9              4  1990           0                  1   \n",
       "9997             10             10  2005           1                  1   \n",
       "9998              1              3  2010           0                  1   \n",
       "9999              6             10  1994           1                  0   \n",
       "\n",
       "      basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0         4313   9005     956               0             7  7559081.5  \n",
       "1         3653   2436     128               1             2  8085989.5  \n",
       "2         2937   8852     135               1             9  5574642.1  \n",
       "3          659   7141     359               0             3  3232561.2  \n",
       "4         8435   2429     292               1             4  7055052.0  \n",
       "...        ...    ...     ...             ...           ...        ...  \n",
       "9995      9311   1698     218               0             4   176425.9  \n",
       "9996      9061   1742     230               0             0  4448474.0  \n",
       "9997      8304   7730     345               1             9  8390030.5  \n",
       "9998      2590   6174     339               1             4  5905107.0  \n",
       "9999      8485   2024     278               1             6   146708.4  \n",
       "\n",
       "[10000 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4e56aa-14ec-4277-b6ed-5e473e038002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   squareMeters       10000 non-null  int64  \n",
      " 1   numberOfRooms      10000 non-null  int64  \n",
      " 2   hasYard            10000 non-null  int64  \n",
      " 3   hasPool            10000 non-null  int64  \n",
      " 4   floors             10000 non-null  int64  \n",
      " 5   cityCode           10000 non-null  int64  \n",
      " 6   cityPartRange      10000 non-null  int64  \n",
      " 7   numPrevOwners      10000 non-null  int64  \n",
      " 8   made               10000 non-null  int64  \n",
      " 9   isNewBuilt         10000 non-null  int64  \n",
      " 10  hasStormProtector  10000 non-null  int64  \n",
      " 11  basement           10000 non-null  int64  \n",
      " 12  attic              10000 non-null  int64  \n",
      " 13  garage             10000 non-null  int64  \n",
      " 14  hasStorageRoom     10000 non-null  int64  \n",
      " 15  hasGuestRoom       10000 non-null  int64  \n",
      " 16  price              10000 non-null  float64\n",
      "dtypes: float64(1), int64(16)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "paris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c25113-f5ab-490f-af46-ba40d557a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = paris.drop(columns=['price'])  \n",
    "y = paris['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e683112-f61c-4394-837b-94b3c8c6438f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "150c98bd-b097-422c-887e-0eb68f952959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd0cf29f-520e-4dac-bc9e-1fb12c7852b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b97cc2da-075d-4933-b1ab-346f440d71a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ddda15b-4135-4f52-8e7b-94dfabf9dc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/saatarko/financescoring/e/FIN-15\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "        project=os.getenv(\"NEPTUNE_PROJECT\"), \n",
    "        api_token=os.getenv(\"NEPTUNE_API_TOKEN\"),\n",
    "        capture_stdout=True,\n",
    "        capture_stderr=True,\n",
    "        capture_traceback=True,\n",
    "        capture_hardware_metrics=True\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ce9d2e8-fcae-4228-8512-349b5a4586c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"content/board\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acb505bf-04ec-420d-978f-2a12d558f3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Оптимизируемые гиперпараметры\n",
    "    lr = trial.suggest_categorical('learning_rate', [0.1, 0.01, 0.001])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 5)\n",
    "    layers = trial.suggest_categorical('layers', [35, 50, 75, 100, 250, 350, 500])\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.3, step=0.1)\n",
    "    activation = trial.suggest_categorical('activation', [\"relu\", \"leaky_relu\"])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', [\"Adam\", \"SGD\", \"RMSprop\"])\n",
    "\n",
    "    optimizer = {\n",
    "        \"Adam\": tf.keras.optimizers.Adam(learning_rate=lr, clipnorm=1.0),\n",
    "        \"SGD\": tf.keras.optimizers.SGD(learning_rate=lr, clipnorm=1.0),\n",
    "        \"RMSprop\": tf.keras.optimizers.RMSprop(learning_rate=lr, clipnorm=1.0),\n",
    "    }[optimizer_name]\n",
    "\n",
    "    # Создаём модель\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(num_layers):\n",
    "        model.add(tf.keras.layers.Dense(layers, activation=activation if activation != \"leaky_relu\" else None))\n",
    "        if activation == \"leaky_relu\":\n",
    "            model.add(tf.keras.layers.LeakyReLU())\n",
    "        model.add(tf.keras.layers.Dropout(dropout))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation=None))  \n",
    "    \n",
    "    model.compile(\n",
    "        loss=\"mse\",\n",
    "        optimizer=optimizer,\n",
    "        metrics=['mae'] \n",
    "    )\n",
    "\n",
    "    # Логируем гиперпараметры \n",
    "    run[f'trials/{trial.number}/parameters'] = {\n",
    "        'learning_rate': lr,\n",
    "        'batch_size': batch_size,\n",
    "        'num_layers': num_layers,\n",
    "        'layers': layers,\n",
    "        'dropout': dropout,\n",
    "        'activation': activation,\n",
    "        'optimizer': optimizer_name\n",
    "    }\n",
    "\n",
    "    neptune_cbk = NeptuneCallback(run=run, base_namespace=f\"trials/{trial.number}/metrics\")\n",
    "    tensorboard = TensorBoard(log_dir=f\"content/board/trial_{trial.number}\", histogram_freq=1)  # Разные логи для trials\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "        neptune_cbk,\n",
    "        tensorboard\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=500,  # Max ограничение\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Оцениваем модель\n",
    "    loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    # Логируем метрики в Neptune\n",
    "    for epoch in range(len(history.history['loss'])):\n",
    "        run[f\"trials/{trial.number}/metrics/train_loss\"].log(history.history['loss'][epoch], step=epoch)\n",
    "        run[f\"trials/{trial.number}/metrics/val_loss\"].log(history.history['val_loss'][epoch], step=epoch)\n",
    "        run[f\"trials/{trial.number}/metrics/train_mae\"].log(history.history['mae'][epoch], step=epoch)\n",
    "        run[f\"trials/{trial.number}/metrics/val_mae\"].log(history.history['val_mae'][epoch], step=epoch)\n",
    "\n",
    "    # Финальные метрики\n",
    "    run[f\"trials/{trial.number}/final/loss\"] = loss\n",
    "    run[f\"trials/{trial.number}/final/mae\"] = mae  \n",
    "\n",
    "    return mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c573aee-ad76-4bb1-bf70-17a54e80a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:37:53,796] A new study created in memory with name: Neptune_Optimization\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:38:19,631] Trial 0 finished with value: 2809771.0 and parameters: {'learning_rate': 0.1, 'batch_size': 64, 'num_layers': 5, 'layers': 350, 'dropout': 0.3, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 0 with value: 2809771.0.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:38:28,329] Trial 1 finished with value: 630936.6875 and parameters: {'learning_rate': 0.1, 'batch_size': 32, 'num_layers': 5, 'layers': 35, 'dropout': 0.2, 'activation': 'relu', 'optimizer': 'RMSprop'}. Best is trial 1 with value: 630936.6875.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:38:46,565] Trial 2 finished with value: 749107459129344.0 and parameters: {'learning_rate': 0.1, 'batch_size': 128, 'num_layers': 5, 'layers': 500, 'dropout': 0.2, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 1 with value: 630936.6875.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:39:08,164] Trial 3 finished with value: 29917.46484375 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 5, 'layers': 350, 'dropout': 0.2, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 3 with value: 29917.46484375.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:39:15,234] Trial 4 finished with value: 86938.6171875 and parameters: {'learning_rate': 0.01, 'batch_size': 32, 'num_layers': 5, 'layers': 35, 'dropout': 0.1, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 3 with value: 29917.46484375.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:39:25,192] Trial 5 finished with value: 1114127.375 and parameters: {'learning_rate': 0.01, 'batch_size': 32, 'num_layers': 5, 'layers': 75, 'dropout': 0.1, 'activation': 'relu', 'optimizer': 'RMSprop'}. Best is trial 3 with value: 29917.46484375.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:39:57,192] Trial 6 finished with value: 8909.40625 and parameters: {'learning_rate': 0.1, 'batch_size': 64, 'num_layers': 3, 'layers': 350, 'dropout': 0.3, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 6 with value: 8909.40625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:40:32,381] Trial 7 finished with value: 8929.3916015625 and parameters: {'learning_rate': 0.01, 'batch_size': 128, 'num_layers': 3, 'layers': 500, 'dropout': 0.1, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 6 with value: 8909.40625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:41:00,811] Trial 8 finished with value: 5530.75390625 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 2, 'layers': 500, 'dropout': 0.2, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:41:27,975] Trial 9 finished with value: 45178.6015625 and parameters: {'learning_rate': 0.01, 'batch_size': 32, 'num_layers': 5, 'layers': 250, 'dropout': 0.3, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:41:40,469] Trial 10 finished with value: 7879.46923828125 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 2, 'layers': 100, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:41:48,161] Trial 11 finished with value: 11626.232421875 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 2, 'layers': 100, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:41:57,093] Trial 12 finished with value: 39696.69140625 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 2, 'layers': 50, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:42:05,178] Trial 13 finished with value: 10031.5654296875 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 2, 'layers': 100, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:42:15,238] Trial 14 finished with value: 12745.6396484375 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 3, 'layers': 100, 'dropout': 0.1, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:42:50,552] Trial 15 finished with value: 15731.091796875 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 4, 'layers': 500, 'dropout': 0.3, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:42:59,604] Trial 16 finished with value: 20786.01171875 and parameters: {'learning_rate': 0.001, 'batch_size': 64, 'num_layers': 2, 'layers': 250, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'RMSprop'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:43:06,007] Trial 17 finished with value: 59393.10546875 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 4, 'layers': 50, 'dropout': 0.1, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:43:12,806] Trial 18 finished with value: 40056.69140625 and parameters: {'learning_rate': 0.001, 'batch_size': 128, 'num_layers': 3, 'layers': 75, 'dropout': 0.3, 'activation': 'relu', 'optimizer': 'Adam'}. Best is trial 8 with value: 5530.75390625.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-24 21:43:47,330] Trial 19 finished with value: 4771.98681640625 and parameters: {'learning_rate': 0.001, 'batch_size': 64, 'num_layers': 2, 'layers': 500, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'RMSprop'}. Best is trial 19 with value: 4771.98681640625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 208 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 208 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/saatarko/financescoring/e/FIN-15/metadata\n",
      "Best parameters: {'learning_rate': 0.001, 'batch_size': 64, 'num_layers': 2, 'layers': 500, 'dropout': 0.2, 'activation': 'leaky_relu', 'optimizer': 'RMSprop'}\n",
      "Best mae: 4771.98681640625\n"
     ]
    }
   ],
   "source": [
    "# Оптимизация с Optuna\n",
    "study = optuna.create_study(direction=\"minimize\", study_name=\"Neptune_Optimization\")\n",
    "\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "# Логируем лучшие параметры\n",
    "best_params = study.best_params\n",
    "best_mae = study.best_value\n",
    "\n",
    "run.stop()\n",
    "\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "print(f\"Best mae: {best_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07730f20-982c-4580-b7d8-054ff597e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получим данные из Optuna\n",
    "best_params = study.best_params\n",
    "best_lr = best_params['learning_rate']\n",
    "best_batch_size = best_params['batch_size']\n",
    "best_dropout = best_params['dropout']\n",
    "best_activation = best_params['activation']\n",
    "best_optimizer = best_params['optimizer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c40ee87c-8895-45fe-bf45-ce9745dfed31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_lr 0.001\n",
      "best_batch_size 64\n",
      "best_dropout 0.2\n",
      "best_activation leaky_relu\n",
      "best_optimizer RMSprop\n"
     ]
    }
   ],
   "source": [
    "print(f\"best_lr {best_lr}\")\n",
    "print(f\"best_batch_size {best_batch_size}\") \n",
    "print(f\"best_dropout {best_dropout}\") \n",
    "print(f\"best_activation {best_activation}\") \n",
    "print(f\"best_optimizer {best_optimizer}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04f48997-cf60-413d-b9ce-d48888420914",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saatarko/.conda/envs/HomeworkDS/lib/python3.12/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4934657.5000 - mae: 4934658.5000 - val_loss: 5110843.5000 - val_mae: 5110843.5000 - learning_rate: 0.0010\n",
      "Epoch 2/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4991121.0000 - mae: 4991122.0000 - val_loss: 5110770.0000 - val_mae: 5110770.0000 - learning_rate: 0.0010\n",
      "Epoch 3/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4950919.0000 - mae: 4950919.5000 - val_loss: 5110626.0000 - val_mae: 5110626.5000 - learning_rate: 0.0010\n",
      "Epoch 4/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4942313.5000 - mae: 4942314.0000 - val_loss: 5110390.5000 - val_mae: 5110391.0000 - learning_rate: 0.0010\n",
      "Epoch 5/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4966561.0000 - mae: 4966562.0000 - val_loss: 5110042.0000 - val_mae: 5110042.0000 - learning_rate: 0.0010\n",
      "Epoch 6/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5006614.0000 - mae: 5006614.0000 - val_loss: 5109561.5000 - val_mae: 5109562.0000 - learning_rate: 0.0010\n",
      "Epoch 7/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5006730.0000 - mae: 5006730.5000 - val_loss: 5108925.0000 - val_mae: 5108926.5000 - learning_rate: 0.0010\n",
      "Epoch 8/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4950917.5000 - mae: 4950918.0000 - val_loss: 5108111.0000 - val_mae: 5108111.0000 - learning_rate: 0.0010\n",
      "Epoch 9/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4957284.0000 - mae: 4957284.5000 - val_loss: 5107102.5000 - val_mae: 5107102.5000 - learning_rate: 0.0010\n",
      "Epoch 10/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4985478.5000 - mae: 4985479.5000 - val_loss: 5105875.0000 - val_mae: 5105875.5000 - learning_rate: 0.0010\n",
      "Epoch 11/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4956479.0000 - mae: 4956479.5000 - val_loss: 5104408.5000 - val_mae: 5104409.0000 - learning_rate: 0.0010\n",
      "Epoch 12/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4946918.0000 - mae: 4946918.0000 - val_loss: 5102680.0000 - val_mae: 5102680.0000 - learning_rate: 0.0010\n",
      "Epoch 13/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5028659.5000 - mae: 5028659.5000 - val_loss: 5100673.0000 - val_mae: 5100673.0000 - learning_rate: 0.0010\n",
      "Epoch 14/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4976051.0000 - mae: 4976051.5000 - val_loss: 5098366.0000 - val_mae: 5098366.5000 - learning_rate: 0.0010\n",
      "Epoch 15/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4976054.0000 - mae: 4976054.5000 - val_loss: 5095733.0000 - val_mae: 5095733.0000 - learning_rate: 0.0010\n",
      "Epoch 16/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4934825.0000 - mae: 4934825.5000 - val_loss: 5092760.0000 - val_mae: 5092761.0000 - learning_rate: 0.0010\n",
      "Epoch 17/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4973209.0000 - mae: 4973209.5000 - val_loss: 5089432.5000 - val_mae: 5089433.5000 - learning_rate: 0.0010\n",
      "Epoch 18/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5031460.0000 - mae: 5031460.5000 - val_loss: 5085720.5000 - val_mae: 5085721.0000 - learning_rate: 0.0010\n",
      "Epoch 19/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4932590.5000 - mae: 4932591.5000 - val_loss: 5081620.0000 - val_mae: 5081620.5000 - learning_rate: 0.0010\n",
      "Epoch 20/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4884124.5000 - mae: 4884125.5000 - val_loss: 5077094.5000 - val_mae: 5077095.0000 - learning_rate: 0.0010\n",
      "Epoch 21/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4932552.0000 - mae: 4932553.0000 - val_loss: 5072114.5000 - val_mae: 5072115.5000 - learning_rate: 0.0010\n",
      "Epoch 22/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4947214.0000 - mae: 4947214.5000 - val_loss: 5066679.0000 - val_mae: 5066679.5000 - learning_rate: 0.0010\n",
      "Epoch 23/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4935808.5000 - mae: 4935810.0000 - val_loss: 5060772.0000 - val_mae: 5060772.0000 - learning_rate: 0.0010\n",
      "Epoch 24/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4936752.0000 - mae: 4936753.0000 - val_loss: 5054383.5000 - val_mae: 5054384.5000 - learning_rate: 0.0010\n",
      "Epoch 25/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4924329.5000 - mae: 4924330.5000 - val_loss: 5047484.0000 - val_mae: 5047485.0000 - learning_rate: 0.0010\n",
      "Epoch 26/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4889353.0000 - mae: 4889354.0000 - val_loss: 5040083.5000 - val_mae: 5040083.5000 - learning_rate: 0.0010\n",
      "Epoch 27/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4848256.0000 - mae: 4848257.0000 - val_loss: 5032116.5000 - val_mae: 5032116.5000 - learning_rate: 0.0010\n",
      "Epoch 28/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4854246.5000 - mae: 4854247.0000 - val_loss: 5023582.5000 - val_mae: 5023583.5000 - learning_rate: 0.0010\n",
      "Epoch 29/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4819853.0000 - mae: 4819854.0000 - val_loss: 5014467.0000 - val_mae: 5014467.0000 - learning_rate: 0.0010\n",
      "Epoch 30/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4836168.0000 - mae: 4836168.5000 - val_loss: 5004752.0000 - val_mae: 5004752.5000 - learning_rate: 0.0010\n",
      "Epoch 31/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4886621.0000 - mae: 4886621.5000 - val_loss: 4994444.5000 - val_mae: 4994445.0000 - learning_rate: 0.0010\n",
      "Epoch 32/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4832601.0000 - mae: 4832601.5000 - val_loss: 4983490.5000 - val_mae: 4983491.0000 - learning_rate: 0.0010\n",
      "Epoch 33/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4796881.5000 - mae: 4796882.0000 - val_loss: 4971908.5000 - val_mae: 4971908.5000 - learning_rate: 0.0010\n",
      "Epoch 34/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4853044.0000 - mae: 4853045.0000 - val_loss: 4959674.0000 - val_mae: 4959675.0000 - learning_rate: 0.0010\n",
      "Epoch 35/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4790522.5000 - mae: 4790523.5000 - val_loss: 4946715.5000 - val_mae: 4946716.5000 - learning_rate: 0.0010\n",
      "Epoch 36/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4771721.0000 - mae: 4771721.0000 - val_loss: 4933105.0000 - val_mae: 4933105.0000 - learning_rate: 0.0010\n",
      "Epoch 37/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4838174.5000 - mae: 4838174.5000 - val_loss: 4918792.5000 - val_mae: 4918793.5000 - learning_rate: 0.0010\n",
      "Epoch 38/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4771048.5000 - mae: 4771048.5000 - val_loss: 4903722.5000 - val_mae: 4903723.0000 - learning_rate: 0.0010\n",
      "Epoch 39/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4724568.0000 - mae: 4724568.5000 - val_loss: 4887983.0000 - val_mae: 4887983.0000 - learning_rate: 0.0010\n",
      "Epoch 40/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4709792.5000 - mae: 4709793.0000 - val_loss: 4871435.0000 - val_mae: 4871435.5000 - learning_rate: 0.0010\n",
      "Epoch 41/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4682067.0000 - mae: 4682067.0000 - val_loss: 4854086.5000 - val_mae: 4854086.5000 - learning_rate: 0.0010\n",
      "Epoch 42/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4616659.0000 - mae: 4616659.5000 - val_loss: 4835962.0000 - val_mae: 4835962.5000 - learning_rate: 0.0010\n",
      "Epoch 43/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4693234.0000 - mae: 4693234.5000 - val_loss: 4817008.5000 - val_mae: 4817009.5000 - learning_rate: 0.0010\n",
      "Epoch 44/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4690289.0000 - mae: 4690289.5000 - val_loss: 4797268.5000 - val_mae: 4797269.0000 - learning_rate: 0.0010\n",
      "Epoch 45/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4646334.5000 - mae: 4646335.0000 - val_loss: 4776758.0000 - val_mae: 4776758.5000 - learning_rate: 0.0010\n",
      "Epoch 46/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4600392.0000 - mae: 4600392.5000 - val_loss: 4755373.0000 - val_mae: 4755373.5000 - learning_rate: 0.0010\n",
      "Epoch 47/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4602331.5000 - mae: 4602332.0000 - val_loss: 4733184.0000 - val_mae: 4733184.0000 - learning_rate: 0.0010\n",
      "Epoch 48/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4551652.0000 - mae: 4551653.0000 - val_loss: 4710079.5000 - val_mae: 4710080.0000 - learning_rate: 0.0010\n",
      "Epoch 49/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4584927.5000 - mae: 4584928.5000 - val_loss: 4686214.0000 - val_mae: 4686214.5000 - learning_rate: 0.0010\n",
      "Epoch 50/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4525479.5000 - mae: 4525480.0000 - val_loss: 4661370.0000 - val_mae: 4661370.5000 - learning_rate: 0.0010\n",
      "Epoch 51/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4500629.5000 - mae: 4500629.5000 - val_loss: 4635710.5000 - val_mae: 4635711.0000 - learning_rate: 0.0010\n",
      "Epoch 52/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4500355.0000 - mae: 4500355.0000 - val_loss: 4609091.5000 - val_mae: 4609092.5000 - learning_rate: 0.0010\n",
      "Epoch 53/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4493707.0000 - mae: 4493707.5000 - val_loss: 4581695.5000 - val_mae: 4581696.0000 - learning_rate: 0.0010\n",
      "Epoch 54/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4466288.5000 - mae: 4466289.0000 - val_loss: 4553327.5000 - val_mae: 4553328.5000 - learning_rate: 0.0010\n",
      "Epoch 55/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4374685.5000 - mae: 4374686.0000 - val_loss: 4524030.5000 - val_mae: 4524030.5000 - learning_rate: 0.0010\n",
      "Epoch 56/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4361196.5000 - mae: 4361197.0000 - val_loss: 4493936.5000 - val_mae: 4493936.5000 - learning_rate: 0.0010\n",
      "Epoch 57/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4351793.0000 - mae: 4351793.5000 - val_loss: 4462830.5000 - val_mae: 4462831.5000 - learning_rate: 0.0010\n",
      "Epoch 58/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4310127.0000 - mae: 4310127.5000 - val_loss: 4430727.0000 - val_mae: 4430727.0000 - learning_rate: 0.0010\n",
      "Epoch 59/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4278549.0000 - mae: 4278549.5000 - val_loss: 4397605.0000 - val_mae: 4397605.0000 - learning_rate: 0.0010\n",
      "Epoch 60/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4283514.0000 - mae: 4283514.5000 - val_loss: 4363714.5000 - val_mae: 4363715.0000 - learning_rate: 0.0010\n",
      "Epoch 61/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4147781.2500 - mae: 4147782.2500 - val_loss: 4328695.5000 - val_mae: 4328696.0000 - learning_rate: 0.0010\n",
      "Epoch 62/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4159710.5000 - mae: 4159711.0000 - val_loss: 4292642.5000 - val_mae: 4292643.0000 - learning_rate: 0.0010\n",
      "Epoch 63/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4111748.2500 - mae: 4111749.0000 - val_loss: 4255613.0000 - val_mae: 4255614.0000 - learning_rate: 0.0010\n",
      "Epoch 64/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4063272.2500 - mae: 4063272.7500 - val_loss: 4217561.0000 - val_mae: 4217561.5000 - learning_rate: 0.0010\n",
      "Epoch 65/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4067775.7500 - mae: 4067776.5000 - val_loss: 4178569.5000 - val_mae: 4178570.0000 - learning_rate: 0.0010\n",
      "Epoch 66/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4048054.5000 - mae: 4048054.7500 - val_loss: 4138462.5000 - val_mae: 4138462.5000 - learning_rate: 0.0010\n",
      "Epoch 67/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4037114.2500 - mae: 4037115.0000 - val_loss: 4097459.2500 - val_mae: 4097460.2500 - learning_rate: 0.0010\n",
      "Epoch 68/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3943545.2500 - mae: 3943545.5000 - val_loss: 4055414.2500 - val_mae: 4055414.7500 - learning_rate: 0.0010\n",
      "Epoch 69/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3891373.0000 - mae: 3891373.5000 - val_loss: 4012457.2500 - val_mae: 4012458.0000 - learning_rate: 0.0010\n",
      "Epoch 70/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3852528.5000 - mae: 3852529.0000 - val_loss: 3968577.2500 - val_mae: 3968577.5000 - learning_rate: 0.0010\n",
      "Epoch 71/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3808244.5000 - mae: 3808245.0000 - val_loss: 3923904.7500 - val_mae: 3923905.0000 - learning_rate: 0.0010\n",
      "Epoch 72/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3786228.7500 - mae: 3786229.0000 - val_loss: 3878147.5000 - val_mae: 3878147.7500 - learning_rate: 0.0010\n",
      "Epoch 73/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3745688.0000 - mae: 3745688.5000 - val_loss: 3831379.5000 - val_mae: 3831379.7500 - learning_rate: 0.0010\n",
      "Epoch 74/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3672510.7500 - mae: 3672511.0000 - val_loss: 3783540.5000 - val_mae: 3783540.7500 - learning_rate: 0.0010\n",
      "Epoch 75/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3626562.2500 - mae: 3626562.5000 - val_loss: 3734829.2500 - val_mae: 3734829.7500 - learning_rate: 0.0010\n",
      "Epoch 76/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3598994.5000 - mae: 3598995.2500 - val_loss: 3685262.0000 - val_mae: 3685262.5000 - learning_rate: 0.0010\n",
      "Epoch 77/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3534346.7500 - mae: 3534347.5000 - val_loss: 3634732.5000 - val_mae: 3634732.7500 - learning_rate: 0.0010\n",
      "Epoch 78/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3490407.7500 - mae: 3490408.2500 - val_loss: 3583435.7500 - val_mae: 3583436.2500 - learning_rate: 0.0010\n",
      "Epoch 79/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3436925.7500 - mae: 3436926.0000 - val_loss: 3531108.2500 - val_mae: 3531108.7500 - learning_rate: 0.0010\n",
      "Epoch 80/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3424948.0000 - mae: 3424948.7500 - val_loss: 3477904.7500 - val_mae: 3477905.5000 - learning_rate: 0.0010\n",
      "Epoch 81/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3361773.5000 - mae: 3361774.0000 - val_loss: 3423768.7500 - val_mae: 3423768.7500 - learning_rate: 0.0010\n",
      "Epoch 82/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3294288.0000 - mae: 3294288.5000 - val_loss: 3368924.7500 - val_mae: 3368925.7500 - learning_rate: 0.0010\n",
      "Epoch 83/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3164992.0000 - mae: 3164993.0000 - val_loss: 3313442.0000 - val_mae: 3313442.7500 - learning_rate: 0.0010\n",
      "Epoch 84/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3174837.7500 - mae: 3174838.2500 - val_loss: 3257312.0000 - val_mae: 3257312.5000 - learning_rate: 0.0010\n",
      "Epoch 85/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3125915.5000 - mae: 3125915.7500 - val_loss: 3200073.2500 - val_mae: 3200073.5000 - learning_rate: 0.0010\n",
      "Epoch 86/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3041778.5000 - mae: 3041779.0000 - val_loss: 3142377.2500 - val_mae: 3142378.5000 - learning_rate: 0.0010\n",
      "Epoch 87/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2975647.0000 - mae: 2975647.2500 - val_loss: 3083811.0000 - val_mae: 3083811.0000 - learning_rate: 0.0010\n",
      "Epoch 88/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2966692.0000 - mae: 2966692.2500 - val_loss: 3024632.5000 - val_mae: 3024633.0000 - learning_rate: 0.0010\n",
      "Epoch 89/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2904249.2500 - mae: 2904249.5000 - val_loss: 2964770.0000 - val_mae: 2964770.2500 - learning_rate: 0.0010\n",
      "Epoch 90/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2813511.0000 - mae: 2813511.5000 - val_loss: 2903955.0000 - val_mae: 2903955.5000 - learning_rate: 0.0010\n",
      "Epoch 91/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2792446.2500 - mae: 2792446.7500 - val_loss: 2843275.5000 - val_mae: 2843276.0000 - learning_rate: 0.0010\n",
      "Epoch 92/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2670135.7500 - mae: 2670136.5000 - val_loss: 2781392.7500 - val_mae: 2781393.2500 - learning_rate: 0.0010\n",
      "Epoch 93/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2687042.7500 - mae: 2687043.0000 - val_loss: 2719440.5000 - val_mae: 2719440.7500 - learning_rate: 0.0010\n",
      "Epoch 94/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2597260.5000 - mae: 2597261.0000 - val_loss: 2656953.5000 - val_mae: 2656954.2500 - learning_rate: 0.0010\n",
      "Epoch 95/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2503491.7500 - mae: 2503492.2500 - val_loss: 2593991.7500 - val_mae: 2593992.2500 - learning_rate: 0.0010\n",
      "Epoch 96/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2472499.2500 - mae: 2472499.5000 - val_loss: 2530316.2500 - val_mae: 2530317.0000 - learning_rate: 0.0010\n",
      "Epoch 97/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2359898.2500 - mae: 2359898.5000 - val_loss: 2466833.0000 - val_mae: 2466833.2500 - learning_rate: 0.0010\n",
      "Epoch 98/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2351702.0000 - mae: 2351702.5000 - val_loss: 2402720.7500 - val_mae: 2402721.0000 - learning_rate: 0.0010\n",
      "Epoch 99/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2287181.5000 - mae: 2287182.0000 - val_loss: 2338269.5000 - val_mae: 2338270.0000 - learning_rate: 0.0010\n",
      "Epoch 100/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2217762.5000 - mae: 2217763.2500 - val_loss: 2273814.5000 - val_mae: 2273815.2500 - learning_rate: 0.0010\n",
      "Epoch 101/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2118764.0000 - mae: 2118764.5000 - val_loss: 2209110.2500 - val_mae: 2209110.5000 - learning_rate: 0.0010\n",
      "Epoch 102/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2098549.2500 - mae: 2098549.7500 - val_loss: 2144638.0000 - val_mae: 2144638.5000 - learning_rate: 0.0010\n",
      "Epoch 103/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2066716.5000 - mae: 2066717.0000 - val_loss: 2079814.3750 - val_mae: 2079814.8750 - learning_rate: 0.0010\n",
      "Epoch 104/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1972392.1250 - mae: 1972392.7500 - val_loss: 2014829.8750 - val_mae: 2014830.6250 - learning_rate: 0.0010\n",
      "Epoch 105/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1893872.0000 - mae: 1893872.5000 - val_loss: 1950183.7500 - val_mae: 1950184.5000 - learning_rate: 0.0010\n",
      "Epoch 106/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1849532.7500 - mae: 1849532.8750 - val_loss: 1885473.8750 - val_mae: 1885474.3750 - learning_rate: 0.0010\n",
      "Epoch 107/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1792335.0000 - mae: 1792335.3750 - val_loss: 1821519.5000 - val_mae: 1821519.8750 - learning_rate: 0.0010\n",
      "Epoch 108/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1738240.3750 - mae: 1738240.8750 - val_loss: 1758198.5000 - val_mae: 1758198.7500 - learning_rate: 0.0010\n",
      "Epoch 109/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1676119.6250 - mae: 1676120.1250 - val_loss: 1696012.8750 - val_mae: 1696013.5000 - learning_rate: 0.0010\n",
      "Epoch 110/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1609534.3750 - mae: 1609535.0000 - val_loss: 1634892.2500 - val_mae: 1634892.5000 - learning_rate: 0.0010\n",
      "Epoch 111/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1549583.8750 - mae: 1549584.2500 - val_loss: 1574735.8750 - val_mae: 1574736.5000 - learning_rate: 0.0010\n",
      "Epoch 112/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1497669.6250 - mae: 1497670.2500 - val_loss: 1515682.1250 - val_mae: 1515682.7500 - learning_rate: 0.0010\n",
      "Epoch 113/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1474794.1250 - mae: 1474794.5000 - val_loss: 1458135.7500 - val_mae: 1458136.5000 - learning_rate: 0.0010\n",
      "Epoch 114/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1388035.1250 - mae: 1388035.5000 - val_loss: 1400708.3750 - val_mae: 1400709.0000 - learning_rate: 0.0010\n",
      "Epoch 115/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1356206.5000 - mae: 1356206.8750 - val_loss: 1345488.7500 - val_mae: 1345489.0000 - learning_rate: 0.0010\n",
      "Epoch 116/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1320622.1250 - mae: 1320622.6250 - val_loss: 1291473.5000 - val_mae: 1291474.1250 - learning_rate: 0.0010\n",
      "Epoch 117/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1251428.5000 - mae: 1251429.0000 - val_loss: 1239673.5000 - val_mae: 1239674.0000 - learning_rate: 0.0010\n",
      "Epoch 118/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1217618.5000 - mae: 1217618.8750 - val_loss: 1191173.3750 - val_mae: 1191173.8750 - learning_rate: 0.0010\n",
      "Epoch 119/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1192501.7500 - mae: 1192502.2500 - val_loss: 1143459.1250 - val_mae: 1143459.8750 - learning_rate: 0.0010\n",
      "Epoch 120/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1152408.1250 - mae: 1152408.7500 - val_loss: 1100683.5000 - val_mae: 1100684.0000 - learning_rate: 0.0010\n",
      "Epoch 121/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1115585.3750 - mae: 1115585.8750 - val_loss: 1059202.1250 - val_mae: 1059202.5000 - learning_rate: 0.0010\n",
      "Epoch 122/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1077406.6250 - mae: 1077407.1250 - val_loss: 1021173.5000 - val_mae: 1021174.1875 - learning_rate: 0.0010\n",
      "Epoch 123/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1058983.8750 - mae: 1058984.3750 - val_loss: 986249.0000 - val_mae: 986249.3750 - learning_rate: 0.0010\n",
      "Epoch 124/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1034259.3750 - mae: 1034259.8125 - val_loss: 956649.1875 - val_mae: 956649.7500 - learning_rate: 0.0010\n",
      "Epoch 125/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 998817.3125 - mae: 998817.8125 - val_loss: 925272.0625 - val_mae: 925272.3750 - learning_rate: 0.0010\n",
      "Epoch 126/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 976945.1875 - mae: 976945.6250 - val_loss: 897560.8750 - val_mae: 897561.1250 - learning_rate: 0.0010\n",
      "Epoch 127/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 960673.8750 - mae: 960674.2500 - val_loss: 869893.6250 - val_mae: 869894.1875 - learning_rate: 0.0010\n",
      "Epoch 128/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 942941.0625 - mae: 942941.6250 - val_loss: 844684.1875 - val_mae: 844684.7500 - learning_rate: 0.0010\n",
      "Epoch 129/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 913772.3750 - mae: 913772.7500 - val_loss: 816584.6875 - val_mae: 816585.0000 - learning_rate: 0.0010\n",
      "Epoch 130/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 909858.9375 - mae: 909859.4375 - val_loss: 791388.9375 - val_mae: 791389.3750 - learning_rate: 0.0010\n",
      "Epoch 131/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 880861.1875 - mae: 880861.6875 - val_loss: 766204.5000 - val_mae: 766205.0625 - learning_rate: 0.0010\n",
      "Epoch 132/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 869089.7500 - mae: 869090.1875 - val_loss: 743126.0625 - val_mae: 743126.5000 - learning_rate: 0.0010\n",
      "Epoch 133/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 848261.5000 - mae: 848262.0000 - val_loss: 720090.0625 - val_mae: 720090.5000 - learning_rate: 0.0010\n",
      "Epoch 134/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 816514.4375 - mae: 816515.0000 - val_loss: 693417.2500 - val_mae: 693417.8125 - learning_rate: 0.0010\n",
      "Epoch 135/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 794845.6875 - mae: 794846.0625 - val_loss: 673147.0625 - val_mae: 673147.5625 - learning_rate: 0.0010\n",
      "Epoch 136/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 778375.5000 - mae: 778376.0000 - val_loss: 652820.4375 - val_mae: 652820.9375 - learning_rate: 0.0010\n",
      "Epoch 137/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 749910.3750 - mae: 749910.8125 - val_loss: 630612.9375 - val_mae: 630613.2500 - learning_rate: 0.0010\n",
      "Epoch 138/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 741998.1250 - mae: 741998.5000 - val_loss: 607921.5000 - val_mae: 607922.0625 - learning_rate: 0.0010\n",
      "Epoch 139/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 728919.8750 - mae: 728920.4375 - val_loss: 587147.8125 - val_mae: 587148.5000 - learning_rate: 0.0010\n",
      "Epoch 140/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 707524.2500 - mae: 707524.7500 - val_loss: 565597.8125 - val_mae: 565598.4375 - learning_rate: 0.0010\n",
      "Epoch 141/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 684201.1250 - mae: 684201.5625 - val_loss: 547632.3750 - val_mae: 547633.0625 - learning_rate: 0.0010\n",
      "Epoch 142/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 675534.1875 - mae: 675534.6875 - val_loss: 528423.9375 - val_mae: 528424.4375 - learning_rate: 0.0010\n",
      "Epoch 143/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 665364.7500 - mae: 665365.2500 - val_loss: 509048.9375 - val_mae: 509049.3750 - learning_rate: 0.0010\n",
      "Epoch 144/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 663097.8750 - mae: 663098.3750 - val_loss: 491935.5312 - val_mae: 491936.0000 - learning_rate: 0.0010\n",
      "Epoch 145/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 636114.0000 - mae: 636114.5625 - val_loss: 478774.0312 - val_mae: 478774.5312 - learning_rate: 0.0010\n",
      "Epoch 146/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 617951.1250 - mae: 617951.7500 - val_loss: 462421.1875 - val_mae: 462421.6875 - learning_rate: 0.0010\n",
      "Epoch 147/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 621511.6875 - mae: 621512.3125 - val_loss: 446761.5000 - val_mae: 446762.0938 - learning_rate: 0.0010\n",
      "Epoch 148/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 610064.3750 - mae: 610064.8125 - val_loss: 434670.3750 - val_mae: 434670.8438 - learning_rate: 0.0010\n",
      "Epoch 149/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 597835.3750 - mae: 597836.0000 - val_loss: 423760.5312 - val_mae: 423761.0312 - learning_rate: 0.0010\n",
      "Epoch 150/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 591816.5000 - mae: 591817.0625 - val_loss: 415313.4688 - val_mae: 415313.9062 - learning_rate: 0.0010\n",
      "Epoch 151/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 594822.3750 - mae: 594823.0000 - val_loss: 405666.6875 - val_mae: 405667.2500 - learning_rate: 0.0010\n",
      "Epoch 152/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 569052.1875 - mae: 569052.7500 - val_loss: 397275.7812 - val_mae: 397276.2812 - learning_rate: 0.0010\n",
      "Epoch 153/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 567204.2500 - mae: 567204.6250 - val_loss: 392245.2188 - val_mae: 392245.6250 - learning_rate: 0.0010\n",
      "Epoch 154/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 559582.6875 - mae: 559583.1250 - val_loss: 385334.0312 - val_mae: 385334.5000 - learning_rate: 0.0010\n",
      "Epoch 155/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 561326.8125 - mae: 561327.2500 - val_loss: 379873.2812 - val_mae: 379873.8750 - learning_rate: 0.0010\n",
      "Epoch 156/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 546103.2500 - mae: 546103.7500 - val_loss: 376491.5000 - val_mae: 376492.0312 - learning_rate: 0.0010\n",
      "Epoch 157/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 540231.4375 - mae: 540231.9375 - val_loss: 373812.8125 - val_mae: 373813.2500 - learning_rate: 0.0010\n",
      "Epoch 158/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 542377.8125 - mae: 542378.2500 - val_loss: 371998.6562 - val_mae: 371999.1875 - learning_rate: 0.0010\n",
      "Epoch 159/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 527025.2500 - mae: 527025.8125 - val_loss: 369541.1562 - val_mae: 369541.6562 - learning_rate: 0.0010\n",
      "Epoch 160/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 537980.6875 - mae: 537981.1875 - val_loss: 368320.2812 - val_mae: 368320.7812 - learning_rate: 0.0010\n",
      "Epoch 161/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 527324.8750 - mae: 527325.4375 - val_loss: 367350.5938 - val_mae: 367351.0625 - learning_rate: 0.0010\n",
      "Epoch 162/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 522331.5938 - mae: 522332.0000 - val_loss: 366323.9688 - val_mae: 366324.4688 - learning_rate: 0.0010\n",
      "Epoch 163/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 525182.1875 - mae: 525182.6250 - val_loss: 365310.6250 - val_mae: 365311.1562 - learning_rate: 0.0010\n",
      "Epoch 164/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 527161.3125 - mae: 527161.8125 - val_loss: 364722.6562 - val_mae: 364723.0625 - learning_rate: 0.0010\n",
      "Epoch 165/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 512161.2500 - mae: 512161.7188 - val_loss: 364404.2500 - val_mae: 364404.7812 - learning_rate: 0.0010\n",
      "Epoch 166/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 523241.6562 - mae: 523242.1250 - val_loss: 363883.5312 - val_mae: 363883.9375 - learning_rate: 0.0010\n",
      "Epoch 167/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 517845.5625 - mae: 517846.0938 - val_loss: 363320.1875 - val_mae: 363320.7188 - learning_rate: 0.0010\n",
      "Epoch 168/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 517705.0938 - mae: 517705.5938 - val_loss: 362932.9375 - val_mae: 362933.3750 - learning_rate: 0.0010\n",
      "Epoch 169/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 518795.6250 - mae: 518796.1250 - val_loss: 362887.8750 - val_mae: 362888.4375 - learning_rate: 0.0010\n",
      "Epoch 170/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 520554.7500 - mae: 520555.3438 - val_loss: 362681.0938 - val_mae: 362681.5625 - learning_rate: 0.0010\n",
      "Epoch 171/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 515292.6250 - mae: 515293.0938 - val_loss: 362481.8750 - val_mae: 362482.3438 - learning_rate: 0.0010\n",
      "Epoch 172/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 507647.8750 - mae: 507648.3750 - val_loss: 362158.7500 - val_mae: 362159.1875 - learning_rate: 0.0010\n",
      "Epoch 173/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 516740.7812 - mae: 516741.3438 - val_loss: 361459.4375 - val_mae: 361459.9062 - learning_rate: 0.0010\n",
      "Epoch 174/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 514111.5938 - mae: 514112.0938 - val_loss: 361003.0000 - val_mae: 361003.5000 - learning_rate: 0.0010\n",
      "Epoch 175/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 508233.0000 - mae: 508233.4688 - val_loss: 360510.0312 - val_mae: 360510.5000 - learning_rate: 0.0010\n",
      "Epoch 176/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 511239.2500 - mae: 511239.8125 - val_loss: 360048.2500 - val_mae: 360048.7500 - learning_rate: 0.0010\n",
      "Epoch 177/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 516058.2812 - mae: 516058.8750 - val_loss: 359679.6250 - val_mae: 359680.1250 - learning_rate: 0.0010\n",
      "Epoch 178/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 502042.0625 - mae: 502042.6250 - val_loss: 359216.9062 - val_mae: 359217.4062 - learning_rate: 0.0010\n",
      "Epoch 179/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 507390.8750 - mae: 507391.3438 - val_loss: 358943.3750 - val_mae: 358943.8438 - learning_rate: 0.0010\n",
      "Epoch 180/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 505354.5938 - mae: 505355.0625 - val_loss: 358426.0312 - val_mae: 358426.4375 - learning_rate: 0.0010\n",
      "Epoch 181/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 513345.5312 - mae: 513345.9688 - val_loss: 357979.9062 - val_mae: 357980.2812 - learning_rate: 0.0010\n",
      "Epoch 182/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 507895.6250 - mae: 507896.0625 - val_loss: 357390.9375 - val_mae: 357391.4062 - learning_rate: 0.0010\n",
      "Epoch 183/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 504637.7812 - mae: 504638.2500 - val_loss: 356879.8438 - val_mae: 356880.2812 - learning_rate: 0.0010\n",
      "Epoch 184/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 499305.8750 - mae: 499306.3125 - val_loss: 356569.4375 - val_mae: 356569.9375 - learning_rate: 0.0010\n",
      "Epoch 185/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 502299.6562 - mae: 502300.2500 - val_loss: 355731.5938 - val_mae: 355732.0000 - learning_rate: 0.0010\n",
      "Epoch 186/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 508020.9375 - mae: 508021.3750 - val_loss: 355241.0938 - val_mae: 355241.5938 - learning_rate: 0.0010\n",
      "Epoch 187/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 498536.9688 - mae: 498537.4062 - val_loss: 354439.3125 - val_mae: 354439.9062 - learning_rate: 0.0010\n",
      "Epoch 188/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 493453.1562 - mae: 493453.5938 - val_loss: 353791.3750 - val_mae: 353791.9062 - learning_rate: 0.0010\n",
      "Epoch 189/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 504151.0000 - mae: 504151.5000 - val_loss: 353344.9688 - val_mae: 353345.5000 - learning_rate: 0.0010\n",
      "Epoch 190/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 499229.5000 - mae: 499230.0000 - val_loss: 353093.3438 - val_mae: 353093.8125 - learning_rate: 0.0010\n",
      "Epoch 191/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 501592.8438 - mae: 501593.2500 - val_loss: 352118.3125 - val_mae: 352118.7500 - learning_rate: 0.0010\n",
      "Epoch 192/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 495930.3438 - mae: 495930.8438 - val_loss: 351245.3750 - val_mae: 351245.8125 - learning_rate: 0.0010\n",
      "Epoch 193/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 504427.2500 - mae: 504427.7500 - val_loss: 350544.0938 - val_mae: 350544.6250 - learning_rate: 0.0010\n",
      "Epoch 194/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 499747.8750 - mae: 499748.4375 - val_loss: 349925.5938 - val_mae: 349926.0625 - learning_rate: 0.0010\n",
      "Epoch 195/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 496943.3125 - mae: 496943.8438 - val_loss: 349196.4062 - val_mae: 349196.9375 - learning_rate: 0.0010\n",
      "Epoch 196/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 492338.0312 - mae: 492338.4688 - val_loss: 347976.3750 - val_mae: 347976.9688 - learning_rate: 0.0010\n",
      "Epoch 197/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 496584.9062 - mae: 496585.4688 - val_loss: 347371.2812 - val_mae: 347371.8750 - learning_rate: 0.0010\n",
      "Epoch 198/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 496806.1562 - mae: 496806.5938 - val_loss: 346848.8125 - val_mae: 346849.3125 - learning_rate: 0.0010\n",
      "Epoch 199/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491630.7188 - mae: 491631.2188 - val_loss: 346247.9062 - val_mae: 346248.4688 - learning_rate: 0.0010\n",
      "Epoch 200/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 499384.2500 - mae: 499384.8125 - val_loss: 345488.9688 - val_mae: 345489.5312 - learning_rate: 0.0010\n",
      "Epoch 201/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491446.5000 - mae: 491447.0000 - val_loss: 344934.7500 - val_mae: 344935.3125 - learning_rate: 0.0010\n",
      "Epoch 202/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 485106.1250 - mae: 485106.5938 - val_loss: 343906.3438 - val_mae: 343906.8125 - learning_rate: 0.0010\n",
      "Epoch 203/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 489361.0938 - mae: 489361.5625 - val_loss: 343501.9062 - val_mae: 343502.4688 - learning_rate: 0.0010\n",
      "Epoch 204/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 487551.6875 - mae: 487552.2188 - val_loss: 343004.7500 - val_mae: 343005.2188 - learning_rate: 0.0010\n",
      "Epoch 205/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 492467.4688 - mae: 492467.9688 - val_loss: 342205.8438 - val_mae: 342206.3125 - learning_rate: 0.0010\n",
      "Epoch 206/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 490715.6562 - mae: 490716.1250 - val_loss: 341613.0938 - val_mae: 341613.5938 - learning_rate: 0.0010\n",
      "Epoch 207/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 490858.4688 - mae: 490859.0312 - val_loss: 340838.1562 - val_mae: 340838.7188 - learning_rate: 0.0010\n",
      "Epoch 208/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 485816.8750 - mae: 485817.3125 - val_loss: 340200.0625 - val_mae: 340200.4688 - learning_rate: 0.0010\n",
      "Epoch 209/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 493980.8125 - mae: 493981.3125 - val_loss: 339443.5938 - val_mae: 339444.0312 - learning_rate: 0.0010\n",
      "Epoch 210/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 474802.0000 - mae: 474802.5000 - val_loss: 339011.0312 - val_mae: 339011.5312 - learning_rate: 0.0010\n",
      "Epoch 211/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 491401.9062 - mae: 491402.3438 - val_loss: 338525.4688 - val_mae: 338525.9375 - learning_rate: 0.0010\n",
      "Epoch 212/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 488046.4688 - mae: 488046.9688 - val_loss: 338190.3438 - val_mae: 338190.8438 - learning_rate: 0.0010\n",
      "Epoch 213/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 479591.1250 - mae: 479591.6875 - val_loss: 337401.7812 - val_mae: 337402.2812 - learning_rate: 0.0010\n",
      "Epoch 214/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 479605.3438 - mae: 479605.7500 - val_loss: 336339.5938 - val_mae: 336340.0312 - learning_rate: 0.0010\n",
      "Epoch 215/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 495838.8125 - mae: 495839.4062 - val_loss: 335684.9688 - val_mae: 335685.4375 - learning_rate: 0.0010\n",
      "Epoch 216/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 476732.3750 - mae: 476732.9375 - val_loss: 335248.2188 - val_mae: 335248.7812 - learning_rate: 0.0010\n",
      "Epoch 217/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 475489.7812 - mae: 475490.2188 - val_loss: 334550.5938 - val_mae: 334551.0312 - learning_rate: 0.0010\n",
      "Epoch 218/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 484626.2188 - mae: 484626.6250 - val_loss: 334087.5938 - val_mae: 334088.0312 - learning_rate: 0.0010\n",
      "Epoch 219/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 478517.1562 - mae: 478517.6875 - val_loss: 333334.0625 - val_mae: 333334.5000 - learning_rate: 0.0010\n",
      "Epoch 220/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 478719.7188 - mae: 478720.0938 - val_loss: 332455.2188 - val_mae: 332455.7500 - learning_rate: 0.0010\n",
      "Epoch 221/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 472445.7812 - mae: 472446.2500 - val_loss: 332027.8125 - val_mae: 332028.2812 - learning_rate: 0.0010\n",
      "Epoch 222/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 480547.9062 - mae: 480548.3438 - val_loss: 331132.0312 - val_mae: 331132.5625 - learning_rate: 0.0010\n",
      "Epoch 223/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 483447.9688 - mae: 483448.5000 - val_loss: 331051.2188 - val_mae: 331051.7188 - learning_rate: 0.0010\n",
      "Epoch 224/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 476176.2500 - mae: 476176.6875 - val_loss: 330537.5625 - val_mae: 330538.0312 - learning_rate: 0.0010\n",
      "Epoch 225/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 477127.0312 - mae: 477127.4688 - val_loss: 330120.6250 - val_mae: 330121.1562 - learning_rate: 0.0010\n",
      "Epoch 226/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 473925.7188 - mae: 473926.2188 - val_loss: 329486.1875 - val_mae: 329486.6562 - learning_rate: 0.0010\n",
      "Epoch 227/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 482637.4688 - mae: 482637.9688 - val_loss: 329077.8750 - val_mae: 329078.4062 - learning_rate: 0.0010\n",
      "Epoch 228/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 473094.1250 - mae: 473094.6562 - val_loss: 328562.5312 - val_mae: 328563.0625 - learning_rate: 0.0010\n",
      "Epoch 229/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 468308.2188 - mae: 468308.5938 - val_loss: 327745.8125 - val_mae: 327746.3125 - learning_rate: 0.0010\n",
      "Epoch 230/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 471919.5938 - mae: 471920.1250 - val_loss: 327521.7812 - val_mae: 327522.3125 - learning_rate: 0.0010\n",
      "Epoch 231/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 467146.8438 - mae: 467147.3438 - val_loss: 326916.6875 - val_mae: 326917.2188 - learning_rate: 0.0010\n",
      "Epoch 232/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 476437.3125 - mae: 476437.7812 - val_loss: 326697.0000 - val_mae: 326697.5000 - learning_rate: 0.0010\n",
      "Epoch 233/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 472367.0938 - mae: 472367.6562 - val_loss: 326059.7812 - val_mae: 326060.2812 - learning_rate: 0.0010\n",
      "Epoch 234/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 462280.7188 - mae: 462281.2500 - val_loss: 324893.5938 - val_mae: 324894.1250 - learning_rate: 0.0010\n",
      "Epoch 235/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 466370.6875 - mae: 466371.2188 - val_loss: 324234.1562 - val_mae: 324234.6250 - learning_rate: 0.0010\n",
      "Epoch 236/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 477654.2812 - mae: 477654.8125 - val_loss: 323705.1875 - val_mae: 323705.7188 - learning_rate: 0.0010\n",
      "Epoch 237/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 465966.4062 - mae: 465966.9375 - val_loss: 323217.1875 - val_mae: 323217.6875 - learning_rate: 0.0010\n",
      "Epoch 238/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 467223.3125 - mae: 467223.7500 - val_loss: 322449.7500 - val_mae: 322450.1875 - learning_rate: 0.0010\n",
      "Epoch 239/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 475282.7812 - mae: 475283.1875 - val_loss: 322601.9688 - val_mae: 322602.4688 - learning_rate: 0.0010\n",
      "Epoch 240/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 469602.6250 - mae: 469603.1875 - val_loss: 321971.4375 - val_mae: 321971.9062 - learning_rate: 0.0010\n",
      "Epoch 241/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 464980.0312 - mae: 464980.5625 - val_loss: 320912.3125 - val_mae: 320912.7812 - learning_rate: 0.0010\n",
      "Epoch 242/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 464974.5312 - mae: 464975.0625 - val_loss: 320034.8750 - val_mae: 320035.4375 - learning_rate: 0.0010\n",
      "Epoch 243/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 467284.8438 - mae: 467285.4375 - val_loss: 319785.2812 - val_mae: 319785.8125 - learning_rate: 0.0010\n",
      "Epoch 244/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 468518.3750 - mae: 468518.8750 - val_loss: 319171.8750 - val_mae: 319172.3438 - learning_rate: 0.0010\n",
      "Epoch 245/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 462997.8750 - mae: 462998.3750 - val_loss: 318583.3125 - val_mae: 318583.8125 - learning_rate: 0.0010\n",
      "Epoch 246/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 460258.3750 - mae: 460258.8438 - val_loss: 318332.0625 - val_mae: 318332.4688 - learning_rate: 0.0010\n",
      "Epoch 247/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 459751.5312 - mae: 459752.0625 - val_loss: 317706.0625 - val_mae: 317706.5625 - learning_rate: 0.0010\n",
      "Epoch 248/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 469371.8750 - mae: 469372.4375 - val_loss: 317222.7812 - val_mae: 317223.3125 - learning_rate: 0.0010\n",
      "Epoch 249/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 461386.5625 - mae: 461387.0312 - val_loss: 316552.0625 - val_mae: 316552.5938 - learning_rate: 0.0010\n",
      "Epoch 250/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 454651.5625 - mae: 454652.0938 - val_loss: 315834.6875 - val_mae: 315835.1250 - learning_rate: 0.0010\n",
      "Epoch 251/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 455630.0000 - mae: 455630.4375 - val_loss: 315563.6250 - val_mae: 315564.1250 - learning_rate: 0.0010\n",
      "Epoch 252/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453099.8750 - mae: 453100.4062 - val_loss: 314983.1562 - val_mae: 314983.7500 - learning_rate: 0.0010\n",
      "Epoch 253/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 458434.0938 - mae: 458434.6250 - val_loss: 314257.1250 - val_mae: 314257.6562 - learning_rate: 0.0010\n",
      "Epoch 254/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 456622.3438 - mae: 456622.8750 - val_loss: 313805.6250 - val_mae: 313806.0938 - learning_rate: 0.0010\n",
      "Epoch 255/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 456676.6250 - mae: 456677.1250 - val_loss: 312772.0625 - val_mae: 312772.5312 - learning_rate: 0.0010\n",
      "Epoch 256/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 472329.3750 - mae: 472329.9062 - val_loss: 312319.1875 - val_mae: 312319.7188 - learning_rate: 0.0010\n",
      "Epoch 257/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 464393.9375 - mae: 464394.4688 - val_loss: 311929.5625 - val_mae: 311930.0938 - learning_rate: 0.0010\n",
      "Epoch 258/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 455917.6250 - mae: 455917.9688 - val_loss: 311156.4062 - val_mae: 311156.9688 - learning_rate: 0.0010\n",
      "Epoch 259/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 464053.9062 - mae: 464054.3438 - val_loss: 310421.9688 - val_mae: 310422.4688 - learning_rate: 0.0010\n",
      "Epoch 260/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 452289.5938 - mae: 452290.0625 - val_loss: 310031.8750 - val_mae: 310032.3750 - learning_rate: 0.0010\n",
      "Epoch 261/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 459329.3438 - mae: 459329.8125 - val_loss: 309026.7188 - val_mae: 309027.2500 - learning_rate: 0.0010\n",
      "Epoch 262/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 464221.0312 - mae: 464221.5938 - val_loss: 308580.0625 - val_mae: 308580.5312 - learning_rate: 0.0010\n",
      "Epoch 263/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 457826.7812 - mae: 457827.4375 - val_loss: 308063.5625 - val_mae: 308064.0625 - learning_rate: 0.0010\n",
      "Epoch 264/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 457020.8750 - mae: 457021.3438 - val_loss: 307347.5312 - val_mae: 307348.0312 - learning_rate: 0.0010\n",
      "Epoch 265/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 459354.7188 - mae: 459355.3438 - val_loss: 306655.5000 - val_mae: 306656.0000 - learning_rate: 0.0010\n",
      "Epoch 266/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 450206.3438 - mae: 450206.7812 - val_loss: 306212.2188 - val_mae: 306212.7812 - learning_rate: 0.0010\n",
      "Epoch 267/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 453269.8125 - mae: 453270.3438 - val_loss: 305847.7812 - val_mae: 305848.2500 - learning_rate: 0.0010\n",
      "Epoch 268/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 452404.4375 - mae: 452404.9688 - val_loss: 305604.8438 - val_mae: 305605.3438 - learning_rate: 0.0010\n",
      "Epoch 269/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 448857.4688 - mae: 448857.9375 - val_loss: 304524.7500 - val_mae: 304525.2188 - learning_rate: 0.0010\n",
      "Epoch 270/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 452207.3125 - mae: 452207.8750 - val_loss: 303818.8438 - val_mae: 303819.3125 - learning_rate: 0.0010\n",
      "Epoch 271/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 452664.0938 - mae: 452664.6562 - val_loss: 303483.7500 - val_mae: 303484.1875 - learning_rate: 0.0010\n",
      "Epoch 272/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 458009.5312 - mae: 458010.0625 - val_loss: 302705.8750 - val_mae: 302706.4062 - learning_rate: 0.0010\n",
      "Epoch 273/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 450051.2500 - mae: 450051.7500 - val_loss: 302069.1250 - val_mae: 302069.6250 - learning_rate: 0.0010\n",
      "Epoch 274/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 448875.5938 - mae: 448876.1250 - val_loss: 301445.6562 - val_mae: 301446.1875 - learning_rate: 0.0010\n",
      "Epoch 275/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 458333.1875 - mae: 458333.7812 - val_loss: 300904.5625 - val_mae: 300905.0938 - learning_rate: 0.0010\n",
      "Epoch 276/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453906.7812 - mae: 453907.2188 - val_loss: 300260.3750 - val_mae: 300260.9062 - learning_rate: 0.0010\n",
      "Epoch 277/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 449927.8438 - mae: 449928.2812 - val_loss: 299884.2188 - val_mae: 299884.7500 - learning_rate: 0.0010\n",
      "Epoch 278/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444356.1250 - mae: 444356.6562 - val_loss: 299790.1250 - val_mae: 299790.5625 - learning_rate: 0.0010\n",
      "Epoch 279/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 453449.4062 - mae: 453449.8438 - val_loss: 298738.1562 - val_mae: 298738.6875 - learning_rate: 0.0010\n",
      "Epoch 280/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 449965.9375 - mae: 449966.5625 - val_loss: 298321.0938 - val_mae: 298321.5312 - learning_rate: 0.0010\n",
      "Epoch 281/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 446364.6250 - mae: 446365.1250 - val_loss: 297904.3438 - val_mae: 297904.8750 - learning_rate: 0.0010\n",
      "Epoch 282/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 442088.7500 - mae: 442089.2188 - val_loss: 297131.5000 - val_mae: 297131.9688 - learning_rate: 0.0010\n",
      "Epoch 283/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444708.1250 - mae: 444708.5938 - val_loss: 296654.2500 - val_mae: 296654.6875 - learning_rate: 0.0010\n",
      "Epoch 284/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 454793.8750 - mae: 454794.3750 - val_loss: 295960.2188 - val_mae: 295960.7500 - learning_rate: 0.0010\n",
      "Epoch 285/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444495.6250 - mae: 444496.2188 - val_loss: 295428.2812 - val_mae: 295428.8438 - learning_rate: 0.0010\n",
      "Epoch 286/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 443558.0938 - mae: 443558.5938 - val_loss: 294968.5000 - val_mae: 294969.0312 - learning_rate: 0.0010\n",
      "Epoch 287/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 442273.9062 - mae: 442274.3438 - val_loss: 294782.9688 - val_mae: 294783.5000 - learning_rate: 0.0010\n",
      "Epoch 288/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 443556.0312 - mae: 443556.5312 - val_loss: 294359.9688 - val_mae: 294360.4375 - learning_rate: 0.0010\n",
      "Epoch 289/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 444942.4688 - mae: 444943.0000 - val_loss: 292975.2812 - val_mae: 292975.7500 - learning_rate: 0.0010\n",
      "Epoch 290/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444778.9062 - mae: 444779.3750 - val_loss: 292586.1250 - val_mae: 292586.6250 - learning_rate: 0.0010\n",
      "Epoch 291/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 443751.8125 - mae: 443752.2500 - val_loss: 292259.5312 - val_mae: 292260.0312 - learning_rate: 0.0010\n",
      "Epoch 292/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 444006.5625 - mae: 444007.0938 - val_loss: 291407.8125 - val_mae: 291408.2812 - learning_rate: 0.0010\n",
      "Epoch 293/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 438988.8438 - mae: 438989.2812 - val_loss: 291033.9375 - val_mae: 291034.4375 - learning_rate: 0.0010\n",
      "Epoch 294/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 434934.0000 - mae: 434934.5312 - val_loss: 290847.7188 - val_mae: 290848.2188 - learning_rate: 0.0010\n",
      "Epoch 295/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 435969.8125 - mae: 435970.3125 - val_loss: 290555.4062 - val_mae: 290555.8750 - learning_rate: 0.0010\n",
      "Epoch 296/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 435009.5312 - mae: 435010.0938 - val_loss: 289913.0000 - val_mae: 289913.5000 - learning_rate: 0.0010\n",
      "Epoch 297/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 451290.6562 - mae: 451291.0938 - val_loss: 289129.6250 - val_mae: 289130.1562 - learning_rate: 0.0010\n",
      "Epoch 298/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431726.0625 - mae: 431726.5000 - val_loss: 288524.7500 - val_mae: 288525.2500 - learning_rate: 0.0010\n",
      "Epoch 299/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 437577.7812 - mae: 437578.2812 - val_loss: 288054.6875 - val_mae: 288055.1875 - learning_rate: 0.0010\n",
      "Epoch 300/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 447745.4062 - mae: 447745.8750 - val_loss: 287227.3750 - val_mae: 287227.8438 - learning_rate: 0.0010\n",
      "Epoch 301/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 441877.5312 - mae: 441878.0312 - val_loss: 286960.6875 - val_mae: 286961.1250 - learning_rate: 0.0010\n",
      "Epoch 302/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 431678.7500 - mae: 431679.2812 - val_loss: 286494.4375 - val_mae: 286494.9375 - learning_rate: 0.0010\n",
      "Epoch 303/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428127.7500 - mae: 428128.1875 - val_loss: 285760.4375 - val_mae: 285760.9688 - learning_rate: 0.0010\n",
      "Epoch 304/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 428969.3438 - mae: 428969.8125 - val_loss: 285314.1562 - val_mae: 285314.6250 - learning_rate: 0.0010\n",
      "Epoch 305/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 436455.3750 - mae: 436455.8750 - val_loss: 284729.5938 - val_mae: 284730.0938 - learning_rate: 0.0010\n",
      "Epoch 306/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 438942.2812 - mae: 438942.6875 - val_loss: 283993.8750 - val_mae: 283994.4062 - learning_rate: 0.0010\n",
      "Epoch 307/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437850.8438 - mae: 437851.2812 - val_loss: 283718.0312 - val_mae: 283718.5625 - learning_rate: 0.0010\n",
      "Epoch 308/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 446969.1875 - mae: 446969.6562 - val_loss: 283058.9688 - val_mae: 283059.5000 - learning_rate: 0.0010\n",
      "Epoch 309/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 438483.8750 - mae: 438484.4062 - val_loss: 282731.3750 - val_mae: 282731.8750 - learning_rate: 0.0010\n",
      "Epoch 310/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 431453.5938 - mae: 431454.0625 - val_loss: 283350.3750 - val_mae: 283350.8438 - learning_rate: 0.0010\n",
      "Epoch 311/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 427446.6562 - mae: 427447.1875 - val_loss: 282564.3438 - val_mae: 282564.8750 - learning_rate: 0.0010\n",
      "Epoch 312/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 437536.4375 - mae: 437536.9062 - val_loss: 281531.9062 - val_mae: 281532.3750 - learning_rate: 0.0010\n",
      "Epoch 313/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 435106.6250 - mae: 435107.0938 - val_loss: 280092.5312 - val_mae: 280093.0625 - learning_rate: 0.0010\n",
      "Epoch 314/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 434718.1250 - mae: 434718.7188 - val_loss: 279658.0312 - val_mae: 279658.5000 - learning_rate: 0.0010\n",
      "Epoch 315/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 435291.8438 - mae: 435292.3438 - val_loss: 279087.7812 - val_mae: 279088.2812 - learning_rate: 0.0010\n",
      "Epoch 316/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 436577.8750 - mae: 436578.4375 - val_loss: 278218.8125 - val_mae: 278219.3125 - learning_rate: 0.0010\n",
      "Epoch 317/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 425600.5938 - mae: 425601.0625 - val_loss: 277994.0625 - val_mae: 277994.5312 - learning_rate: 0.0010\n",
      "Epoch 318/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 427280.3125 - mae: 427280.8750 - val_loss: 277353.4688 - val_mae: 277353.9688 - learning_rate: 0.0010\n",
      "Epoch 319/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 432974.6562 - mae: 432975.2500 - val_loss: 276926.9062 - val_mae: 276927.4062 - learning_rate: 0.0010\n",
      "Epoch 320/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 425194.7812 - mae: 425195.2812 - val_loss: 276759.4688 - val_mae: 276759.9375 - learning_rate: 0.0010\n",
      "Epoch 321/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 427151.3438 - mae: 427151.7812 - val_loss: 275684.5938 - val_mae: 275685.0938 - learning_rate: 0.0010\n",
      "Epoch 322/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 428238.4688 - mae: 428239.0000 - val_loss: 274403.4375 - val_mae: 274403.9375 - learning_rate: 0.0010\n",
      "Epoch 323/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 421715.2188 - mae: 421715.7500 - val_loss: 273766.6562 - val_mae: 273767.1562 - learning_rate: 0.0010\n",
      "Epoch 324/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 426279.2188 - mae: 426279.7188 - val_loss: 273951.6875 - val_mae: 273952.1875 - learning_rate: 0.0010\n",
      "Epoch 325/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 414106.9688 - mae: 414107.4062 - val_loss: 273239.4062 - val_mae: 273239.9062 - learning_rate: 0.0010\n",
      "Epoch 326/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 422666.3438 - mae: 422666.9375 - val_loss: 273291.8125 - val_mae: 273292.3125 - learning_rate: 0.0010\n",
      "Epoch 327/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 426029.4062 - mae: 426029.8438 - val_loss: 272158.7188 - val_mae: 272159.1875 - learning_rate: 0.0010\n",
      "Epoch 328/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 422029.5938 - mae: 422030.0938 - val_loss: 271353.9375 - val_mae: 271354.4688 - learning_rate: 0.0010\n",
      "Epoch 329/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 421737.2500 - mae: 421737.6875 - val_loss: 271710.7188 - val_mae: 271711.1875 - learning_rate: 0.0010\n",
      "Epoch 330/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 421841.0625 - mae: 421841.5625 - val_loss: 271144.5312 - val_mae: 271145.0625 - learning_rate: 0.0010\n",
      "Epoch 331/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 419683.6250 - mae: 419684.0000 - val_loss: 271030.7812 - val_mae: 271031.2500 - learning_rate: 0.0010\n",
      "Epoch 332/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 413426.0312 - mae: 413426.4688 - val_loss: 270398.4062 - val_mae: 270398.8750 - learning_rate: 0.0010\n",
      "Epoch 333/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 423980.9375 - mae: 423981.4062 - val_loss: 269369.7812 - val_mae: 269370.3125 - learning_rate: 0.0010\n",
      "Epoch 334/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 413734.5938 - mae: 413735.0938 - val_loss: 268313.7500 - val_mae: 268314.2812 - learning_rate: 0.0010\n",
      "Epoch 335/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 419371.5312 - mae: 419372.1250 - val_loss: 267419.2500 - val_mae: 267419.7500 - learning_rate: 0.0010\n",
      "Epoch 336/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 413617.9062 - mae: 413618.3750 - val_loss: 266870.2188 - val_mae: 266870.7188 - learning_rate: 0.0010\n",
      "Epoch 337/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 424127.7500 - mae: 424128.2188 - val_loss: 266347.7500 - val_mae: 266348.2500 - learning_rate: 0.0010\n",
      "Epoch 338/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 414762.7500 - mae: 414763.2500 - val_loss: 267197.7500 - val_mae: 267198.2500 - learning_rate: 0.0010\n",
      "Epoch 339/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413806.5000 - mae: 413807.0312 - val_loss: 266140.0938 - val_mae: 266140.5938 - learning_rate: 0.0010\n",
      "Epoch 340/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 410184.5312 - mae: 410185.0312 - val_loss: 265968.8438 - val_mae: 265969.3125 - learning_rate: 0.0010\n",
      "Epoch 341/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408641.5938 - mae: 408642.0938 - val_loss: 264587.7188 - val_mae: 264588.2188 - learning_rate: 0.0010\n",
      "Epoch 342/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 413798.0000 - mae: 413798.4688 - val_loss: 263942.2500 - val_mae: 263942.7500 - learning_rate: 0.0010\n",
      "Epoch 343/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 418941.0938 - mae: 418941.6562 - val_loss: 262998.6562 - val_mae: 262999.1875 - learning_rate: 0.0010\n",
      "Epoch 344/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 412918.0312 - mae: 412918.5625 - val_loss: 262789.5312 - val_mae: 262790.0312 - learning_rate: 0.0010\n",
      "Epoch 345/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 411322.2500 - mae: 411322.6875 - val_loss: 262000.5156 - val_mae: 262001.0469 - learning_rate: 0.0010\n",
      "Epoch 346/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 421524.0625 - mae: 421524.5938 - val_loss: 261329.0156 - val_mae: 261329.5000 - learning_rate: 0.0010\n",
      "Epoch 347/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 418379.7812 - mae: 418380.2500 - val_loss: 260773.2656 - val_mae: 260773.7656 - learning_rate: 0.0010\n",
      "Epoch 348/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 414511.5938 - mae: 414512.0625 - val_loss: 261106.1250 - val_mae: 261106.6250 - learning_rate: 0.0010\n",
      "Epoch 349/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 413908.1250 - mae: 413908.6562 - val_loss: 260152.9375 - val_mae: 260153.4375 - learning_rate: 0.0010\n",
      "Epoch 350/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 415681.2812 - mae: 415681.7812 - val_loss: 259595.9844 - val_mae: 259596.4688 - learning_rate: 0.0010\n",
      "Epoch 351/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 413084.2812 - mae: 413084.8438 - val_loss: 258589.2031 - val_mae: 258589.6875 - learning_rate: 0.0010\n",
      "Epoch 352/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 409424.5312 - mae: 409425.0938 - val_loss: 257554.8750 - val_mae: 257555.3750 - learning_rate: 0.0010\n",
      "Epoch 353/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 416220.3750 - mae: 416220.8438 - val_loss: 257155.3750 - val_mae: 257155.8750 - learning_rate: 0.0010\n",
      "Epoch 354/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408072.2500 - mae: 408072.7500 - val_loss: 256533.6875 - val_mae: 256534.1875 - learning_rate: 0.0010\n",
      "Epoch 355/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 409904.8125 - mae: 409905.3438 - val_loss: 256102.0625 - val_mae: 256102.5625 - learning_rate: 0.0010\n",
      "Epoch 356/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 409726.9688 - mae: 409727.4688 - val_loss: 255277.6875 - val_mae: 255278.1875 - learning_rate: 0.0010\n",
      "Epoch 357/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 403265.1875 - mae: 403265.6250 - val_loss: 255146.7500 - val_mae: 255147.2656 - learning_rate: 0.0010\n",
      "Epoch 358/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 403457.6875 - mae: 403458.1875 - val_loss: 254602.3125 - val_mae: 254602.8281 - learning_rate: 0.0010\n",
      "Epoch 359/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 402977.9688 - mae: 402978.4375 - val_loss: 253722.5312 - val_mae: 253723.0312 - learning_rate: 0.0010\n",
      "Epoch 360/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 401530.7812 - mae: 401531.2500 - val_loss: 253078.8594 - val_mae: 253079.3594 - learning_rate: 0.0010\n",
      "Epoch 361/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408917.1875 - mae: 408917.7500 - val_loss: 252185.2344 - val_mae: 252185.7344 - learning_rate: 0.0010\n",
      "Epoch 362/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 405683.4062 - mae: 405683.8750 - val_loss: 251809.4219 - val_mae: 251809.9219 - learning_rate: 0.0010\n",
      "Epoch 363/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 400147.5000 - mae: 400148.0000 - val_loss: 251330.5938 - val_mae: 251331.0938 - learning_rate: 0.0010\n",
      "Epoch 364/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 402865.7500 - mae: 402866.2500 - val_loss: 250350.6406 - val_mae: 250351.1406 - learning_rate: 0.0010\n",
      "Epoch 365/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 408690.7812 - mae: 408691.3438 - val_loss: 249819.8438 - val_mae: 249820.3438 - learning_rate: 0.0010\n",
      "Epoch 366/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 405979.8750 - mae: 405980.4062 - val_loss: 249431.9375 - val_mae: 249432.4531 - learning_rate: 0.0010\n",
      "Epoch 367/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 397072.6562 - mae: 397073.1562 - val_loss: 248707.0469 - val_mae: 248707.5312 - learning_rate: 0.0010\n",
      "Epoch 368/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 401590.6250 - mae: 401591.1250 - val_loss: 248381.3438 - val_mae: 248381.8438 - learning_rate: 0.0010\n",
      "Epoch 369/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 406601.6250 - mae: 406602.1562 - val_loss: 247471.2344 - val_mae: 247471.7031 - learning_rate: 0.0010\n",
      "Epoch 370/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 397124.0000 - mae: 397124.5625 - val_loss: 246369.9844 - val_mae: 246370.4844 - learning_rate: 0.0010\n",
      "Epoch 371/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 399387.3750 - mae: 399387.8750 - val_loss: 246295.1875 - val_mae: 246295.6875 - learning_rate: 0.0010\n",
      "Epoch 372/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 406380.3125 - mae: 406380.8125 - val_loss: 245668.1562 - val_mae: 245668.6562 - learning_rate: 0.0010\n",
      "Epoch 373/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 404169.3125 - mae: 404169.8438 - val_loss: 244807.1719 - val_mae: 244807.6875 - learning_rate: 0.0010\n",
      "Epoch 374/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 393404.3750 - mae: 393404.8750 - val_loss: 243941.1406 - val_mae: 243941.6094 - learning_rate: 0.0010\n",
      "Epoch 375/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 400219.9688 - mae: 400220.4375 - val_loss: 243055.6250 - val_mae: 243056.1250 - learning_rate: 0.0010\n",
      "Epoch 376/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 396784.7812 - mae: 396785.3125 - val_loss: 242042.2656 - val_mae: 242042.7656 - learning_rate: 0.0010\n",
      "Epoch 377/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 399770.2500 - mae: 399770.8125 - val_loss: 241375.0156 - val_mae: 241375.4844 - learning_rate: 0.0010\n",
      "Epoch 378/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 395342.6250 - mae: 395343.1875 - val_loss: 240825.1875 - val_mae: 240825.6875 - learning_rate: 0.0010\n",
      "Epoch 379/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 386201.3750 - mae: 386201.8750 - val_loss: 240576.0000 - val_mae: 240576.5156 - learning_rate: 0.0010\n",
      "Epoch 380/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 390796.9375 - mae: 390797.3438 - val_loss: 239717.0469 - val_mae: 239717.5625 - learning_rate: 0.0010\n",
      "Epoch 381/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 392041.5312 - mae: 392042.0625 - val_loss: 238766.1406 - val_mae: 238766.6406 - learning_rate: 0.0010\n",
      "Epoch 382/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 410804.5625 - mae: 410805.0000 - val_loss: 238533.0469 - val_mae: 238533.5469 - learning_rate: 0.0010\n",
      "Epoch 383/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 394122.8750 - mae: 394123.3750 - val_loss: 237479.9531 - val_mae: 237480.4844 - learning_rate: 0.0010\n",
      "Epoch 384/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 402371.3125 - mae: 402371.8125 - val_loss: 236473.1250 - val_mae: 236473.6094 - learning_rate: 0.0010\n",
      "Epoch 385/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 388726.7188 - mae: 388727.2812 - val_loss: 236162.0781 - val_mae: 236162.5938 - learning_rate: 0.0010\n",
      "Epoch 386/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 396435.0625 - mae: 396435.6250 - val_loss: 236112.5156 - val_mae: 236113.0156 - learning_rate: 0.0010\n",
      "Epoch 387/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 392516.4062 - mae: 392516.8438 - val_loss: 235334.7656 - val_mae: 235335.2812 - learning_rate: 0.0010\n",
      "Epoch 388/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 392975.0938 - mae: 392975.5938 - val_loss: 234327.9688 - val_mae: 234328.4688 - learning_rate: 0.0010\n",
      "Epoch 389/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 387809.5000 - mae: 387810.0000 - val_loss: 234379.6094 - val_mae: 234380.1094 - learning_rate: 0.0010\n",
      "Epoch 390/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390529.0312 - mae: 390529.5312 - val_loss: 232985.1250 - val_mae: 232985.5938 - learning_rate: 0.0010\n",
      "Epoch 391/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 388069.2188 - mae: 388069.6875 - val_loss: 232111.3594 - val_mae: 232111.8594 - learning_rate: 0.0010\n",
      "Epoch 392/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 391388.2500 - mae: 391388.8438 - val_loss: 231307.7031 - val_mae: 231308.1875 - learning_rate: 0.0010\n",
      "Epoch 393/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 386936.6875 - mae: 386937.1875 - val_loss: 230874.0781 - val_mae: 230874.5625 - learning_rate: 0.0010\n",
      "Epoch 394/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 391678.7500 - mae: 391679.2812 - val_loss: 230965.5625 - val_mae: 230966.0781 - learning_rate: 0.0010\n",
      "Epoch 395/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 399420.6250 - mae: 399421.0938 - val_loss: 230212.8906 - val_mae: 230213.4062 - learning_rate: 0.0010\n",
      "Epoch 396/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 385036.4062 - mae: 385036.8750 - val_loss: 229230.6406 - val_mae: 229231.1406 - learning_rate: 0.0010\n",
      "Epoch 397/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 384314.3125 - mae: 384314.8125 - val_loss: 228538.3750 - val_mae: 228538.8438 - learning_rate: 0.0010\n",
      "Epoch 398/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 384462.3750 - mae: 384462.9375 - val_loss: 227946.5625 - val_mae: 227947.0781 - learning_rate: 0.0010\n",
      "Epoch 399/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 389655.0312 - mae: 389655.5625 - val_loss: 227224.7812 - val_mae: 227225.2812 - learning_rate: 0.0010\n",
      "Epoch 400/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 394914.9062 - mae: 394915.3750 - val_loss: 226133.0312 - val_mae: 226133.5156 - learning_rate: 0.0010\n",
      "Epoch 401/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 388218.9688 - mae: 388219.5000 - val_loss: 225202.5938 - val_mae: 225203.0625 - learning_rate: 0.0010\n",
      "Epoch 402/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 378874.1562 - mae: 378874.6875 - val_loss: 224742.3750 - val_mae: 224742.8750 - learning_rate: 0.0010\n",
      "Epoch 403/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 387651.7500 - mae: 387652.2500 - val_loss: 223825.9844 - val_mae: 223826.4688 - learning_rate: 0.0010\n",
      "Epoch 404/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 376508.5312 - mae: 376509.1250 - val_loss: 222961.5781 - val_mae: 222962.0781 - learning_rate: 0.0010\n",
      "Epoch 405/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 379834.2812 - mae: 379834.6875 - val_loss: 222490.5156 - val_mae: 222491.0312 - learning_rate: 0.0010\n",
      "Epoch 406/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 378736.0938 - mae: 378736.5938 - val_loss: 221729.1250 - val_mae: 221729.6250 - learning_rate: 0.0010\n",
      "Epoch 407/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 382563.4688 - mae: 382563.9688 - val_loss: 220814.6094 - val_mae: 220815.1250 - learning_rate: 0.0010\n",
      "Epoch 408/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 375502.7500 - mae: 375503.2188 - val_loss: 220421.4531 - val_mae: 220421.9531 - learning_rate: 0.0010\n",
      "Epoch 409/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 380246.8125 - mae: 380247.3125 - val_loss: 219733.4062 - val_mae: 219733.9062 - learning_rate: 0.0010\n",
      "Epoch 410/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 377743.6562 - mae: 377744.1875 - val_loss: 219971.8750 - val_mae: 219972.3750 - learning_rate: 0.0010\n",
      "Epoch 411/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 385418.7188 - mae: 385419.2812 - val_loss: 219149.1719 - val_mae: 219149.6875 - learning_rate: 0.0010\n",
      "Epoch 412/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 390852.3125 - mae: 390852.7812 - val_loss: 218203.2969 - val_mae: 218203.8125 - learning_rate: 0.0010\n",
      "Epoch 413/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 385395.1562 - mae: 385395.6250 - val_loss: 217845.0469 - val_mae: 217845.5312 - learning_rate: 0.0010\n",
      "Epoch 414/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 378225.4375 - mae: 378225.8750 - val_loss: 217289.0625 - val_mae: 217289.5469 - learning_rate: 0.0010\n",
      "Epoch 415/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 382174.5938 - mae: 382175.0000 - val_loss: 216123.4688 - val_mae: 216123.9844 - learning_rate: 0.0010\n",
      "Epoch 416/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 376996.0000 - mae: 376996.5000 - val_loss: 216009.7656 - val_mae: 216010.2500 - learning_rate: 0.0010\n",
      "Epoch 417/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 378366.4062 - mae: 378366.9062 - val_loss: 215075.1719 - val_mae: 215075.6406 - learning_rate: 0.0010\n",
      "Epoch 418/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 366872.5625 - mae: 366873.0312 - val_loss: 214023.9062 - val_mae: 214024.3906 - learning_rate: 0.0010\n",
      "Epoch 419/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 373284.2500 - mae: 373284.7188 - val_loss: 213426.7812 - val_mae: 213427.2812 - learning_rate: 0.0010\n",
      "Epoch 420/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 379103.7812 - mae: 379104.3125 - val_loss: 212668.5312 - val_mae: 212669.0312 - learning_rate: 0.0010\n",
      "Epoch 421/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 373684.2812 - mae: 373684.7812 - val_loss: 211870.4375 - val_mae: 211870.9375 - learning_rate: 0.0010\n",
      "Epoch 422/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 367271.5312 - mae: 367272.0000 - val_loss: 210924.4375 - val_mae: 210924.9375 - learning_rate: 0.0010\n",
      "Epoch 423/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 373441.6250 - mae: 373442.1250 - val_loss: 210442.4688 - val_mae: 210442.9688 - learning_rate: 0.0010\n",
      "Epoch 424/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 372584.4375 - mae: 372584.9062 - val_loss: 210169.5781 - val_mae: 210170.0625 - learning_rate: 0.0010\n",
      "Epoch 425/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 370832.6250 - mae: 370833.1562 - val_loss: 210019.6875 - val_mae: 210020.1719 - learning_rate: 0.0010\n",
      "Epoch 426/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 367894.9688 - mae: 367895.5312 - val_loss: 209758.9844 - val_mae: 209759.4844 - learning_rate: 0.0010\n",
      "Epoch 427/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 375831.4688 - mae: 375832.0000 - val_loss: 207757.2344 - val_mae: 207757.7500 - learning_rate: 0.0010\n",
      "Epoch 428/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 372067.4062 - mae: 372067.9688 - val_loss: 206857.5000 - val_mae: 206858.0000 - learning_rate: 0.0010\n",
      "Epoch 429/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373407.2812 - mae: 373407.7500 - val_loss: 205584.7656 - val_mae: 205585.2500 - learning_rate: 0.0010\n",
      "Epoch 430/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 372121.1562 - mae: 372121.5938 - val_loss: 205040.0938 - val_mae: 205040.6094 - learning_rate: 0.0010\n",
      "Epoch 431/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 362672.7188 - mae: 362673.2188 - val_loss: 204635.6562 - val_mae: 204636.1562 - learning_rate: 0.0010\n",
      "Epoch 432/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 368838.8750 - mae: 368839.4375 - val_loss: 203630.7344 - val_mae: 203631.2188 - learning_rate: 0.0010\n",
      "Epoch 433/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 369578.7812 - mae: 369579.3438 - val_loss: 203018.6562 - val_mae: 203019.1562 - learning_rate: 0.0010\n",
      "Epoch 434/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 368907.5625 - mae: 368907.9688 - val_loss: 202634.3438 - val_mae: 202634.8281 - learning_rate: 0.0010\n",
      "Epoch 435/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 366663.9688 - mae: 366664.4688 - val_loss: 201911.2031 - val_mae: 201911.7031 - learning_rate: 0.0010\n",
      "Epoch 436/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 369091.8125 - mae: 369092.2812 - val_loss: 201064.2969 - val_mae: 201064.7969 - learning_rate: 0.0010\n",
      "Epoch 437/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 364112.2812 - mae: 364112.7812 - val_loss: 200120.8125 - val_mae: 200121.3125 - learning_rate: 0.0010\n",
      "Epoch 438/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 363733.9688 - mae: 363734.5000 - val_loss: 198929.1875 - val_mae: 198929.6875 - learning_rate: 0.0010\n",
      "Epoch 439/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 367542.9375 - mae: 367543.4375 - val_loss: 197819.8281 - val_mae: 197820.3438 - learning_rate: 0.0010\n",
      "Epoch 440/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 371178.2500 - mae: 371178.7188 - val_loss: 197181.8125 - val_mae: 197182.2969 - learning_rate: 0.0010\n",
      "Epoch 441/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 358006.1875 - mae: 358006.6875 - val_loss: 196362.2500 - val_mae: 196362.7500 - learning_rate: 0.0010\n",
      "Epoch 442/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 359417.0625 - mae: 359417.5625 - val_loss: 195629.6094 - val_mae: 195630.1406 - learning_rate: 0.0010\n",
      "Epoch 443/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 360911.3125 - mae: 360911.8125 - val_loss: 194821.9688 - val_mae: 194822.4688 - learning_rate: 0.0010\n",
      "Epoch 444/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 365270.0312 - mae: 365270.5625 - val_loss: 194989.7812 - val_mae: 194990.2812 - learning_rate: 0.0010\n",
      "Epoch 445/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 363196.3438 - mae: 363196.7812 - val_loss: 194782.3125 - val_mae: 194782.8125 - learning_rate: 0.0010\n",
      "Epoch 446/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 363770.2812 - mae: 363770.7500 - val_loss: 194052.9219 - val_mae: 194053.4219 - learning_rate: 0.0010\n",
      "Epoch 447/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 359447.1875 - mae: 359447.6875 - val_loss: 193343.0469 - val_mae: 193343.5625 - learning_rate: 0.0010\n",
      "Epoch 448/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 354520.6562 - mae: 354521.1875 - val_loss: 191852.0625 - val_mae: 191852.5469 - learning_rate: 0.0010\n",
      "Epoch 449/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 358264.1562 - mae: 358264.7188 - val_loss: 190734.1875 - val_mae: 190734.6875 - learning_rate: 0.0010\n",
      "Epoch 450/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 356841.5000 - mae: 356841.9375 - val_loss: 189664.1094 - val_mae: 189664.6094 - learning_rate: 0.0010\n",
      "Epoch 451/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 357855.3438 - mae: 357855.7188 - val_loss: 188793.0156 - val_mae: 188793.5156 - learning_rate: 0.0010\n",
      "Epoch 452/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 356596.5000 - mae: 356597.0625 - val_loss: 188031.6406 - val_mae: 188032.1406 - learning_rate: 0.0010\n",
      "Epoch 453/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 350381.7188 - mae: 350382.3125 - val_loss: 187147.2812 - val_mae: 187147.7812 - learning_rate: 0.0010\n",
      "Epoch 454/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 346493.4375 - mae: 346494.0000 - val_loss: 186389.3125 - val_mae: 186389.8281 - learning_rate: 0.0010\n",
      "Epoch 455/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 355319.2500 - mae: 355319.7500 - val_loss: 185566.9062 - val_mae: 185567.4062 - learning_rate: 0.0010\n",
      "Epoch 456/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 353085.0312 - mae: 353085.4688 - val_loss: 185212.2500 - val_mae: 185212.7500 - learning_rate: 0.0010\n",
      "Epoch 457/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 355729.1562 - mae: 355729.7188 - val_loss: 184493.0625 - val_mae: 184493.5469 - learning_rate: 0.0010\n",
      "Epoch 458/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 351272.8438 - mae: 351273.3125 - val_loss: 184406.8125 - val_mae: 184407.3125 - learning_rate: 0.0010\n",
      "Epoch 459/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 352258.4688 - mae: 352259.0000 - val_loss: 184294.7344 - val_mae: 184295.2500 - learning_rate: 0.0010\n",
      "Epoch 460/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 350274.0938 - mae: 350274.6250 - val_loss: 183186.9844 - val_mae: 183187.4844 - learning_rate: 0.0010\n",
      "Epoch 461/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 360529.8438 - mae: 360530.3438 - val_loss: 182334.2344 - val_mae: 182334.7344 - learning_rate: 0.0010\n",
      "Epoch 462/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 363710.2500 - mae: 363710.7500 - val_loss: 181529.3906 - val_mae: 181529.8906 - learning_rate: 0.0010\n",
      "Epoch 463/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 349120.5312 - mae: 349121.0000 - val_loss: 180986.6406 - val_mae: 180987.1406 - learning_rate: 0.0010\n",
      "Epoch 464/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 344099.1250 - mae: 344099.6562 - val_loss: 179674.9531 - val_mae: 179675.4375 - learning_rate: 0.0010\n",
      "Epoch 465/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 349726.7812 - mae: 349727.2500 - val_loss: 179171.8906 - val_mae: 179172.4062 - learning_rate: 0.0010\n",
      "Epoch 466/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 355372.0312 - mae: 355372.5000 - val_loss: 178323.4844 - val_mae: 178323.9844 - learning_rate: 0.0010\n",
      "Epoch 467/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 352607.3750 - mae: 352607.9062 - val_loss: 178048.6562 - val_mae: 178049.1562 - learning_rate: 0.0010\n",
      "Epoch 468/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 351876.3438 - mae: 351876.8750 - val_loss: 177088.4844 - val_mae: 177088.9844 - learning_rate: 0.0010\n",
      "Epoch 469/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 341157.7188 - mae: 341158.1562 - val_loss: 177066.2188 - val_mae: 177066.7500 - learning_rate: 0.0010\n",
      "Epoch 470/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 352834.4688 - mae: 352835.0625 - val_loss: 175876.2344 - val_mae: 175876.7188 - learning_rate: 0.0010\n",
      "Epoch 471/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 347350.7500 - mae: 347351.2812 - val_loss: 175071.2500 - val_mae: 175071.7656 - learning_rate: 0.0010\n",
      "Epoch 472/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 348640.8438 - mae: 348641.3750 - val_loss: 174425.2656 - val_mae: 174425.7656 - learning_rate: 0.0010\n",
      "Epoch 473/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 346000.2188 - mae: 346000.8125 - val_loss: 173418.2969 - val_mae: 173418.8125 - learning_rate: 0.0010\n",
      "Epoch 474/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 341824.2500 - mae: 341824.7500 - val_loss: 172816.6094 - val_mae: 172817.1094 - learning_rate: 0.0010\n",
      "Epoch 475/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 342230.3438 - mae: 342230.8125 - val_loss: 172303.2188 - val_mae: 172303.7188 - learning_rate: 0.0010\n",
      "Epoch 476/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342782.3750 - mae: 342782.9375 - val_loss: 171627.0625 - val_mae: 171627.5469 - learning_rate: 0.0010\n",
      "Epoch 477/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 335128.2188 - mae: 335128.6875 - val_loss: 170406.7656 - val_mae: 170407.2812 - learning_rate: 0.0010\n",
      "Epoch 478/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 349317.9688 - mae: 349318.4688 - val_loss: 169822.7031 - val_mae: 169823.2031 - learning_rate: 0.0010\n",
      "Epoch 479/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 341383.5938 - mae: 341384.1250 - val_loss: 168945.4844 - val_mae: 168945.9844 - learning_rate: 0.0010\n",
      "Epoch 480/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 342372.5000 - mae: 342373.0000 - val_loss: 167779.5625 - val_mae: 167780.0781 - learning_rate: 0.0010\n",
      "Epoch 481/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 346981.1875 - mae: 346981.6562 - val_loss: 167788.4844 - val_mae: 167788.9688 - learning_rate: 0.0010\n",
      "Epoch 482/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 345565.5625 - mae: 345566.0938 - val_loss: 166365.5625 - val_mae: 166366.0625 - learning_rate: 0.0010\n",
      "Epoch 483/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 344834.6562 - mae: 344835.1250 - val_loss: 165964.5000 - val_mae: 165964.9844 - learning_rate: 0.0010\n",
      "Epoch 484/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 339916.2500 - mae: 339916.7188 - val_loss: 164954.3594 - val_mae: 164954.8750 - learning_rate: 0.0010\n",
      "Epoch 485/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 349147.5312 - mae: 349148.0000 - val_loss: 164018.9062 - val_mae: 164019.4219 - learning_rate: 0.0010\n",
      "Epoch 486/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 344048.5312 - mae: 344049.1250 - val_loss: 163632.6562 - val_mae: 163633.1562 - learning_rate: 0.0010\n",
      "Epoch 487/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 331994.0312 - mae: 331994.4688 - val_loss: 163320.6719 - val_mae: 163321.1719 - learning_rate: 0.0010\n",
      "Epoch 488/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335593.7500 - mae: 335594.2500 - val_loss: 162837.1250 - val_mae: 162837.6094 - learning_rate: 0.0010\n",
      "Epoch 489/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 338721.8750 - mae: 338722.3438 - val_loss: 161898.9688 - val_mae: 161899.4844 - learning_rate: 0.0010\n",
      "Epoch 490/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 332342.9688 - mae: 332343.4688 - val_loss: 161262.6406 - val_mae: 161263.1406 - learning_rate: 0.0010\n",
      "Epoch 491/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 341006.1875 - mae: 341006.6875 - val_loss: 160397.8125 - val_mae: 160398.2969 - learning_rate: 0.0010\n",
      "Epoch 492/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 339699.9062 - mae: 339700.3438 - val_loss: 160022.2969 - val_mae: 160022.7969 - learning_rate: 0.0010\n",
      "Epoch 493/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 330795.8125 - mae: 330796.3750 - val_loss: 158620.1562 - val_mae: 158620.6562 - learning_rate: 0.0010\n",
      "Epoch 494/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333291.9375 - mae: 333292.4375 - val_loss: 158129.3438 - val_mae: 158129.8438 - learning_rate: 0.0010\n",
      "Epoch 495/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 341470.5625 - mae: 341471.0938 - val_loss: 157259.8750 - val_mae: 157260.3750 - learning_rate: 0.0010\n",
      "Epoch 496/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 332522.3750 - mae: 332522.9062 - val_loss: 156509.3281 - val_mae: 156509.8438 - learning_rate: 0.0010\n",
      "Epoch 497/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 334587.6875 - mae: 334588.2188 - val_loss: 155344.6562 - val_mae: 155345.1719 - learning_rate: 0.0010\n",
      "Epoch 498/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 333859.5312 - mae: 333860.0312 - val_loss: 155609.2188 - val_mae: 155609.7188 - learning_rate: 0.0010\n",
      "Epoch 499/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 340490.0625 - mae: 340490.5000 - val_loss: 154035.8594 - val_mae: 154036.3750 - learning_rate: 0.0010\n",
      "Epoch 500/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 331268.7812 - mae: 331269.2812 - val_loss: 152898.5938 - val_mae: 152899.0938 - learning_rate: 0.0010\n",
      "Epoch 501/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 328209.3438 - mae: 328209.8438 - val_loss: 152619.1406 - val_mae: 152619.6250 - learning_rate: 0.0010\n",
      "Epoch 502/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 326804.0625 - mae: 326804.6250 - val_loss: 152648.0000 - val_mae: 152648.5000 - learning_rate: 0.0010\n",
      "Epoch 503/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 331964.3750 - mae: 331964.9375 - val_loss: 151891.0625 - val_mae: 151891.5469 - learning_rate: 0.0010\n",
      "Epoch 504/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 331335.5625 - mae: 331336.0312 - val_loss: 150860.4531 - val_mae: 150860.9375 - learning_rate: 0.0010\n",
      "Epoch 505/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 333153.0312 - mae: 333153.5312 - val_loss: 149688.6094 - val_mae: 149689.1094 - learning_rate: 0.0010\n",
      "Epoch 506/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 339053.9688 - mae: 339054.5000 - val_loss: 148847.8594 - val_mae: 148848.3594 - learning_rate: 0.0010\n",
      "Epoch 507/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 329742.9375 - mae: 329743.4688 - val_loss: 148562.3750 - val_mae: 148562.8594 - learning_rate: 0.0010\n",
      "Epoch 508/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335916.0938 - mae: 335916.5312 - val_loss: 147561.4062 - val_mae: 147561.9219 - learning_rate: 0.0010\n",
      "Epoch 509/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 337316.4688 - mae: 337316.9375 - val_loss: 147641.6875 - val_mae: 147642.1719 - learning_rate: 0.0010\n",
      "Epoch 510/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 335338.8125 - mae: 335339.3438 - val_loss: 147704.4531 - val_mae: 147704.9375 - learning_rate: 0.0010\n",
      "Epoch 511/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 329307.8750 - mae: 329308.3750 - val_loss: 146427.0625 - val_mae: 146427.5469 - learning_rate: 0.0010\n",
      "Epoch 512/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 325220.1875 - mae: 325220.6875 - val_loss: 145519.5000 - val_mae: 145520.0000 - learning_rate: 0.0010\n",
      "Epoch 513/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 324052.7812 - mae: 324053.3125 - val_loss: 144323.1875 - val_mae: 144323.6875 - learning_rate: 0.0010\n",
      "Epoch 514/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 326939.7500 - mae: 326940.2500 - val_loss: 144366.8281 - val_mae: 144367.3281 - learning_rate: 0.0010\n",
      "Epoch 515/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 323130.0312 - mae: 323130.5625 - val_loss: 143437.5312 - val_mae: 143438.0312 - learning_rate: 0.0010\n",
      "Epoch 516/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 322539.8750 - mae: 322540.4375 - val_loss: 143191.1406 - val_mae: 143191.6250 - learning_rate: 0.0010\n",
      "Epoch 517/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 319916.4688 - mae: 319916.9688 - val_loss: 142441.9375 - val_mae: 142442.4375 - learning_rate: 0.0010\n",
      "Epoch 518/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 330399.9688 - mae: 330400.5000 - val_loss: 141505.1094 - val_mae: 141505.6094 - learning_rate: 0.0010\n",
      "Epoch 519/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 324091.1562 - mae: 324091.7188 - val_loss: 140976.5469 - val_mae: 140977.0625 - learning_rate: 0.0010\n",
      "Epoch 520/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319645.0000 - mae: 319645.5312 - val_loss: 139642.0781 - val_mae: 139642.5781 - learning_rate: 0.0010\n",
      "Epoch 521/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 319313.5000 - mae: 319313.9688 - val_loss: 139200.5781 - val_mae: 139201.0781 - learning_rate: 0.0010\n",
      "Epoch 522/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 320832.6562 - mae: 320833.1875 - val_loss: 138583.3906 - val_mae: 138583.8906 - learning_rate: 0.0010\n",
      "Epoch 523/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 320763.2188 - mae: 320763.6875 - val_loss: 137823.2500 - val_mae: 137823.7500 - learning_rate: 0.0010\n",
      "Epoch 524/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 316135.5000 - mae: 316135.9688 - val_loss: 136863.7656 - val_mae: 136864.2500 - learning_rate: 0.0010\n",
      "Epoch 525/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 324953.7500 - mae: 324954.1875 - val_loss: 136448.8281 - val_mae: 136449.3281 - learning_rate: 0.0010\n",
      "Epoch 526/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 321382.5312 - mae: 321383.0000 - val_loss: 135200.9062 - val_mae: 135201.4062 - learning_rate: 0.0010\n",
      "Epoch 527/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 329085.5938 - mae: 329086.0938 - val_loss: 134061.4062 - val_mae: 134061.8906 - learning_rate: 0.0010\n",
      "Epoch 528/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318864.6875 - mae: 318865.2500 - val_loss: 133656.3125 - val_mae: 133656.8281 - learning_rate: 0.0010\n",
      "Epoch 529/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318395.7500 - mae: 318396.2500 - val_loss: 132459.6562 - val_mae: 132460.1719 - learning_rate: 0.0010\n",
      "Epoch 530/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 321238.5625 - mae: 321239.1250 - val_loss: 132317.1250 - val_mae: 132317.6250 - learning_rate: 0.0010\n",
      "Epoch 531/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 319322.0625 - mae: 319322.5312 - val_loss: 131300.2188 - val_mae: 131300.7188 - learning_rate: 0.0010\n",
      "Epoch 532/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 313544.4688 - mae: 313544.9688 - val_loss: 131155.4531 - val_mae: 131155.9531 - learning_rate: 0.0010\n",
      "Epoch 533/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 312019.4062 - mae: 312019.9375 - val_loss: 130398.9453 - val_mae: 130399.4453 - learning_rate: 0.0010\n",
      "Epoch 534/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318309.6875 - mae: 318310.1875 - val_loss: 129401.8594 - val_mae: 129402.3516 - learning_rate: 0.0010\n",
      "Epoch 535/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 318878.5312 - mae: 318879.0312 - val_loss: 129480.1797 - val_mae: 129480.6797 - learning_rate: 0.0010\n",
      "Epoch 536/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 315541.1562 - mae: 315541.6562 - val_loss: 128766.5156 - val_mae: 128767.0156 - learning_rate: 0.0010\n",
      "Epoch 537/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 319440.2500 - mae: 319440.6562 - val_loss: 127816.3359 - val_mae: 127816.8438 - learning_rate: 0.0010\n",
      "Epoch 538/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 313416.8438 - mae: 313417.3438 - val_loss: 128227.9844 - val_mae: 128228.4766 - learning_rate: 0.0010\n",
      "Epoch 539/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 322502.1875 - mae: 322502.6562 - val_loss: 127546.7422 - val_mae: 127547.2422 - learning_rate: 0.0010\n",
      "Epoch 540/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 319241.0938 - mae: 319241.5938 - val_loss: 126606.1797 - val_mae: 126606.6719 - learning_rate: 0.0010\n",
      "Epoch 541/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 314553.7188 - mae: 314554.2188 - val_loss: 125700.4766 - val_mae: 125700.9844 - learning_rate: 0.0010\n",
      "Epoch 542/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 310513.2812 - mae: 310513.8438 - val_loss: 124909.5938 - val_mae: 124910.0859 - learning_rate: 0.0010\n",
      "Epoch 543/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 317655.2812 - mae: 317655.7812 - val_loss: 124108.0391 - val_mae: 124108.5469 - learning_rate: 0.0010\n",
      "Epoch 544/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 309703.5000 - mae: 309704.0000 - val_loss: 123278.5625 - val_mae: 123279.0547 - learning_rate: 0.0010\n",
      "Epoch 545/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 309469.6562 - mae: 309470.1562 - val_loss: 122243.7188 - val_mae: 122244.2266 - learning_rate: 0.0010\n",
      "Epoch 546/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 313197.0938 - mae: 313197.6875 - val_loss: 122175.0312 - val_mae: 122175.5312 - learning_rate: 0.0010\n",
      "Epoch 547/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 309760.5625 - mae: 309761.0312 - val_loss: 121870.8594 - val_mae: 121871.3516 - learning_rate: 0.0010\n",
      "Epoch 548/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 305179.5312 - mae: 305180.0000 - val_loss: 121172.5859 - val_mae: 121173.0781 - learning_rate: 0.0010\n",
      "Epoch 549/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 305216.9375 - mae: 305217.4062 - val_loss: 120695.2422 - val_mae: 120695.7344 - learning_rate: 0.0010\n",
      "Epoch 550/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 311979.9688 - mae: 311980.4062 - val_loss: 119348.7969 - val_mae: 119349.3047 - learning_rate: 0.0010\n",
      "Epoch 551/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 308648.4062 - mae: 308648.8438 - val_loss: 118691.8438 - val_mae: 118692.3359 - learning_rate: 0.0010\n",
      "Epoch 552/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 316103.4688 - mae: 316103.9688 - val_loss: 118559.5781 - val_mae: 118560.0781 - learning_rate: 0.0010\n",
      "Epoch 553/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 310895.6250 - mae: 310896.0938 - val_loss: 117769.8203 - val_mae: 117770.3203 - learning_rate: 0.0010\n",
      "Epoch 554/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 311271.8125 - mae: 311272.3438 - val_loss: 116989.4062 - val_mae: 116989.9062 - learning_rate: 0.0010\n",
      "Epoch 555/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309991.9688 - mae: 309992.3750 - val_loss: 115953.0078 - val_mae: 115953.5078 - learning_rate: 0.0010\n",
      "Epoch 556/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 306673.9375 - mae: 306674.4375 - val_loss: 116151.1016 - val_mae: 116151.6094 - learning_rate: 0.0010\n",
      "Epoch 557/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304420.2500 - mae: 304420.7812 - val_loss: 114451.0547 - val_mae: 114451.5547 - learning_rate: 0.0010\n",
      "Epoch 558/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 304957.8438 - mae: 304958.3438 - val_loss: 114116.2812 - val_mae: 114116.7812 - learning_rate: 0.0010\n",
      "Epoch 559/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 309089.4688 - mae: 309090.0312 - val_loss: 113468.2188 - val_mae: 113468.7188 - learning_rate: 0.0010\n",
      "Epoch 560/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 304035.1250 - mae: 304035.6250 - val_loss: 113360.1250 - val_mae: 113360.6250 - learning_rate: 0.0010\n",
      "Epoch 561/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300517.0938 - mae: 300517.5938 - val_loss: 112723.3516 - val_mae: 112723.8594 - learning_rate: 0.0010\n",
      "Epoch 562/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 312286.6250 - mae: 312287.1562 - val_loss: 112867.7969 - val_mae: 112868.3047 - learning_rate: 0.0010\n",
      "Epoch 563/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 303311.0000 - mae: 303311.4688 - val_loss: 112062.6250 - val_mae: 112063.1172 - learning_rate: 0.0010\n",
      "Epoch 564/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299271.7188 - mae: 299272.2500 - val_loss: 111401.2578 - val_mae: 111401.7578 - learning_rate: 0.0010\n",
      "Epoch 565/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 309286.0312 - mae: 309286.5000 - val_loss: 110512.9531 - val_mae: 110513.4531 - learning_rate: 0.0010\n",
      "Epoch 566/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295864.0000 - mae: 295864.5000 - val_loss: 109278.6094 - val_mae: 109279.1094 - learning_rate: 0.0010\n",
      "Epoch 567/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 304876.2188 - mae: 304876.6875 - val_loss: 109098.3281 - val_mae: 109098.8281 - learning_rate: 0.0010\n",
      "Epoch 568/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 309583.3125 - mae: 309583.7812 - val_loss: 108279.4531 - val_mae: 108279.9609 - learning_rate: 0.0010\n",
      "Epoch 569/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 300905.8750 - mae: 300906.3750 - val_loss: 107674.6641 - val_mae: 107675.1562 - learning_rate: 0.0010\n",
      "Epoch 570/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 305113.0312 - mae: 305113.5625 - val_loss: 106718.2656 - val_mae: 106718.7656 - learning_rate: 0.0010\n",
      "Epoch 571/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 307068.5625 - mae: 307069.0625 - val_loss: 106574.7266 - val_mae: 106575.2344 - learning_rate: 0.0010\n",
      "Epoch 572/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 304134.4375 - mae: 304134.9688 - val_loss: 106389.7656 - val_mae: 106390.2656 - learning_rate: 0.0010\n",
      "Epoch 573/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 306267.0000 - mae: 306267.5312 - val_loss: 105420.1953 - val_mae: 105420.6875 - learning_rate: 0.0010\n",
      "Epoch 574/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 295061.0625 - mae: 295061.5625 - val_loss: 105447.3984 - val_mae: 105447.9062 - learning_rate: 0.0010\n",
      "Epoch 575/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 297056.1562 - mae: 297056.6875 - val_loss: 104228.7188 - val_mae: 104229.2188 - learning_rate: 0.0010\n",
      "Epoch 576/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 302244.2812 - mae: 302244.8125 - val_loss: 103594.8203 - val_mae: 103595.3281 - learning_rate: 0.0010\n",
      "Epoch 577/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299498.2500 - mae: 299498.8125 - val_loss: 102740.5859 - val_mae: 102741.0781 - learning_rate: 0.0010\n",
      "Epoch 578/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299679.7812 - mae: 299680.2812 - val_loss: 102664.5391 - val_mae: 102665.0391 - learning_rate: 0.0010\n",
      "Epoch 579/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 301735.4688 - mae: 301736.0000 - val_loss: 102017.9688 - val_mae: 102018.4688 - learning_rate: 0.0010\n",
      "Epoch 580/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 290181.2500 - mae: 290181.8125 - val_loss: 101201.5859 - val_mae: 101202.0781 - learning_rate: 0.0010\n",
      "Epoch 581/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299461.9688 - mae: 299462.4062 - val_loss: 100256.5156 - val_mae: 100257.0156 - learning_rate: 0.0010\n",
      "Epoch 582/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 300690.7812 - mae: 300691.2500 - val_loss: 102227.8672 - val_mae: 102228.3594 - learning_rate: 0.0010\n",
      "Epoch 583/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 301446.5938 - mae: 301447.1250 - val_loss: 101045.9062 - val_mae: 101046.4062 - learning_rate: 0.0010\n",
      "Epoch 584/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295901.7188 - mae: 295902.1562 - val_loss: 99389.1406 - val_mae: 99389.6406 - learning_rate: 0.0010\n",
      "Epoch 585/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 304491.1250 - mae: 304491.5938 - val_loss: 100255.7969 - val_mae: 100256.3047 - learning_rate: 0.0010\n",
      "Epoch 586/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 293646.9688 - mae: 293647.4688 - val_loss: 99832.7734 - val_mae: 99833.2734 - learning_rate: 0.0010\n",
      "Epoch 587/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 295961.0000 - mae: 295961.5000 - val_loss: 98219.6094 - val_mae: 98220.1016 - learning_rate: 0.0010\n",
      "Epoch 588/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 299788.4375 - mae: 299789.0000 - val_loss: 97209.6953 - val_mae: 97210.1953 - learning_rate: 0.0010\n",
      "Epoch 589/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 289621.5312 - mae: 289622.0312 - val_loss: 96848.1016 - val_mae: 96848.6016 - learning_rate: 0.0010\n",
      "Epoch 590/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 298716.8750 - mae: 298717.3438 - val_loss: 95756.4766 - val_mae: 95756.9766 - learning_rate: 0.0010\n",
      "Epoch 591/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 300001.2812 - mae: 300001.6875 - val_loss: 94988.7422 - val_mae: 94989.2500 - learning_rate: 0.0010\n",
      "Epoch 592/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 300054.9062 - mae: 300055.4062 - val_loss: 96188.3594 - val_mae: 96188.8672 - learning_rate: 0.0010\n",
      "Epoch 593/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 293021.5312 - mae: 293022.0312 - val_loss: 94098.8438 - val_mae: 94099.3359 - learning_rate: 0.0010\n",
      "Epoch 594/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 292174.5625 - mae: 292175.0625 - val_loss: 94744.5391 - val_mae: 94745.0312 - learning_rate: 0.0010\n",
      "Epoch 595/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 294328.5938 - mae: 294329.0625 - val_loss: 92260.2500 - val_mae: 92260.7500 - learning_rate: 0.0010\n",
      "Epoch 596/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 291679.1250 - mae: 291679.6250 - val_loss: 93227.7344 - val_mae: 93228.2344 - learning_rate: 0.0010\n",
      "Epoch 597/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 285657.0938 - mae: 285657.6250 - val_loss: 91471.6719 - val_mae: 91472.1719 - learning_rate: 0.0010\n",
      "Epoch 598/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 283324.5938 - mae: 283325.0938 - val_loss: 91714.6875 - val_mae: 91715.1875 - learning_rate: 0.0010\n",
      "Epoch 599/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 291825.2188 - mae: 291825.6875 - val_loss: 91366.3984 - val_mae: 91366.8984 - learning_rate: 0.0010\n",
      "Epoch 600/600\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 294580.4062 - mae: 294580.8750 - val_loss: 91134.9688 - val_mae: 91135.4609 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Создаём модель\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train_scaled.shape[1],)),  # Входной слой\n",
    "    keras.layers.Dense(64),\n",
    "    keras.layers.LeakyReLU(alpha=0.01),\n",
    "    keras.layers.Dropout(best_dropout),\n",
    "    keras.layers.Dense(32),\n",
    "    keras.layers.LeakyReLU(alpha=0.01),\n",
    "    keras.layers.Dense(1)  # Выходной слой\n",
    "])\n",
    "\n",
    "callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ]\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(best_lr), \n",
    "              loss=tf.keras.losses.Huber(delta=1.0), \n",
    "              metrics=['mae'])\n",
    "\n",
    "# История обучения хранится в объекте history\n",
    "history = model.fit(X_train_scaled, y_train, epochs=600, batch_size=best_batch_size, \n",
    "                    validation_data=(X_test_scaled, y_test), verbose=1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b781de8-70ac-4f62-bda7-f50aa389e490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 90871.7422 - mae: 90872.2422\n",
      "\n",
      "Средняя абсолютная ошибка (MAE): 91135.484375\n"
     ]
    }
   ],
   "source": [
    "# Оценка на тесте\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "print(\"\\nСредняя абсолютная ошибка (MAE):\", test_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "233564bf-0a61-41d9-9099-75b4e3fee3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# График ошибки\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.title('График ошибки (Loss)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95fbec94-1d5f-47bb-b40a-fb9846008be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Фактические значения')\n",
    "plt.ylabel('Предсказанные значения')\n",
    "plt.title('Сравнение предсказаний с реальными значениями')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red')  # Линия идеального предсказания\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03367d-1457-42f4-8c65-d7a60a081124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
